{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "SNN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d64798077d64ec1b791a418ecab024d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01d63eb1a0054b969b3482de101d40cc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_49a078257afb440c8f7a1abfd14a1971",
              "IPY_MODEL_da33728b94324b35b78b832352ba6222"
            ]
          }
        },
        "01d63eb1a0054b969b3482de101d40cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49a078257afb440c8f7a1abfd14a1971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fd185ba5c45c436c93363920bf1a1908",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 11,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 11,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad5d950281174d1ebb4b1e5a50c79396"
          }
        },
        "da33728b94324b35b78b832352ba6222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_455109194cb5431788cc29523519fb98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 11/11 [00:00&lt;00:00, 14.54ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cb92eab80494409a87f9a4f2caa7335"
          }
        },
        "fd185ba5c45c436c93363920bf1a1908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad5d950281174d1ebb4b1e5a50c79396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "455109194cb5431788cc29523519fb98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cb92eab80494409a87f9a4f2caa7335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e057adff0dc548f4a51f95dc1e4e5115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b1b6d3893e6478f814f7a8961fdd3e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_87448e32d1174137ac85dd0e3f3117a1",
              "IPY_MODEL_31e64225b4604c6282f73e7bad55fec9"
            ]
          }
        },
        "2b1b6d3893e6478f814f7a8961fdd3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87448e32d1174137ac85dd0e3f3117a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_980dede6caf3432284e1440dacd22fdd",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_896b7c91c99a44d6817ccb6fd661c0a1"
          }
        },
        "31e64225b4604c6282f73e7bad55fec9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_db563eca7c7548099b96dae78402823e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4/4 [00:00&lt;00:00, 10.35ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97b92180b62c464ba12c98870c0e320a"
          }
        },
        "980dede6caf3432284e1440dacd22fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "896b7c91c99a44d6817ccb6fd661c0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db563eca7c7548099b96dae78402823e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97b92180b62c464ba12c98870c0e320a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYPcuipBctOc"
      },
      "source": [
        "# 6.864 Project\n",
        "$\\textbf{Main idea}$: Testing the limits of zero-shot and few-shot learning for labeling at scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xejDQSG9BTPj",
        "outputId": "128e9ff6-459b-468c-e77b-7e3744a64fef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIswL-1kBeF5"
      },
      "source": [
        "%%bash\n",
        "# Logistics #2: install the transformers package, create a folder, download the dataset and a patch\n",
        "pip -q install transformers\n",
        "pip -q install datasets\n",
        "pip -q install tqdm\n",
        "pip -q install sentencepiece \n",
        "\n",
        "# mkdir \"/content/gdrive/MyDrive/6864_Project/\"\n",
        "cd \"/content/gdrive/MyDrive/6864_Project/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVLLNcXYBO51"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "\n",
        "import os\n",
        "os.chdir('/content/gdrive/MyDrive/6864_Project/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBj1Wg7vBO5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd932e1-caf1-4ebe-a1f2-ca51471f8028"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "banking = load_dataset('banking77')\n",
        "print(banking)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset banking77 (/root/.cache/huggingface/datasets/banking77/default/1.1.0/17ffc2ed47c2ed928bee64127ff1dbc97204cb974c2f980becae7c864007aed9)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 10003\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 3080\n",
            "    })\n",
            "})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOcHENvBBO5_"
      },
      "source": [
        "# Need to remap all labels\n",
        "label_tbl = pd.read_csv('banking77.csv')\n",
        "label_map = {}\n",
        "\n",
        "# for simplicity only keep some 30 labels in training/testing data\n",
        "random.seed(6864)\n",
        "n_classes = 30\n",
        "labels_to_keep = random.sample(list(range(len(label_tbl))), k= n_classes)\n",
        "\n",
        "for i in range(len(label_tbl)):\n",
        "    label = label_tbl['Label'].iloc[i]\n",
        "    label = re.sub(r'\\_',' ',label)\n",
        "    ix = label_tbl['Label_ix'].iloc[i]\n",
        "    if ix in labels_to_keep:\n",
        "      label_map.update({ix: label})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsTv76LsBO6A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152,
          "referenced_widgets": [
            "1d64798077d64ec1b791a418ecab024d",
            "01d63eb1a0054b969b3482de101d40cc",
            "49a078257afb440c8f7a1abfd14a1971",
            "da33728b94324b35b78b832352ba6222",
            "fd185ba5c45c436c93363920bf1a1908",
            "ad5d950281174d1ebb4b1e5a50c79396",
            "455109194cb5431788cc29523519fb98",
            "8cb92eab80494409a87f9a4f2caa7335",
            "e057adff0dc548f4a51f95dc1e4e5115",
            "2b1b6d3893e6478f814f7a8961fdd3e8",
            "87448e32d1174137ac85dd0e3f3117a1",
            "31e64225b4604c6282f73e7bad55fec9",
            "980dede6caf3432284e1440dacd22fdd",
            "896b7c91c99a44d6817ccb6fd661c0a1",
            "db563eca7c7548099b96dae78402823e",
            "97b92180b62c464ba12c98870c0e320a"
          ]
        },
        "outputId": "2c506fdd-dff5-4c30-9982-4b8a86d19561"
      },
      "source": [
        "# filter trianing set to only intents we want \n",
        "banking2 = banking.filter(lambda row: row['label'] in labels_to_keep)\n",
        "\n",
        "print(len(banking2['train']))\n",
        "print(len(banking2['test']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d64798077d64ec1b791a418ecab024d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e057adff0dc548f4a51f95dc1e4e5115",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "4001\n",
            "1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2ZofpjoL8Ny"
      },
      "source": [
        "# Build out training and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvIIoDzlL3kW",
        "outputId": "9a2c4a86-72ec-4b0e-fc1d-bc6805dff234"
      },
      "source": [
        "# # First create a relatively small training set in light of few-shot learning. We collect k samples from each label\n",
        "label_counter = {}\n",
        "n_samples = 20 # This designates the number of each sentence with label i that we have in training\n",
        "val_size = 75\n",
        "\n",
        "train_queries, train_labels = [],[]\n",
        "test_queries, test_labels = [], []\n",
        "for i in range(len(banking2['train'])):\n",
        "  text = banking2['train'][i]['text']\n",
        "  label = banking2['train'][i]['label']\n",
        "  if label not in label_counter:\n",
        "    label_counter.update({label: 1})\n",
        "    train_queries.append(text)\n",
        "    train_labels.append(label)\n",
        "  else:\n",
        "    if label_counter[label] < n_samples:\n",
        "      train_queries.append(text)\n",
        "      train_labels.append(label)\n",
        "      label_counter[label] += 1\n",
        "    else:\n",
        "      test_queries.append(text)\n",
        "      test_labels.append(label)\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "test_ix = np.random.choice(len(test_queries), 1000) # grab 1000 points for testing \n",
        "mask = np.ones(len(test_queries), dtype=bool)\n",
        "mask[test_ix] = False\n",
        "holdout_ix = np.where(mask)[0]\n",
        "# Everything else from test_ix goes into the holdout\n",
        "holdout_queries = banking2['test']['text']\n",
        "holdout_labels = banking2['test']['label']\n",
        "holdout_queries += [test_queries[i] for i in holdout_ix.tolist()]\n",
        "holdout_labels += [test_labels[i] for i in holdout_ix.tolist()]\n",
        "# Create testing set of 1000\n",
        "test_queries=[test_queries[i] for i in test_ix.tolist()]\n",
        "test_labels=[test_labels[i] for i in test_ix.tolist()]\n",
        "\n",
        "train = pd.DataFrame({'text': train_queries, 'label': train_labels})\n",
        "test = pd.DataFrame({'text': test_queries, 'label': test_labels})\n",
        "holdout = pd.DataFrame({'text': holdout_queries, 'label': holdout_labels})\n",
        "\n",
        "train_queries, train_labels = list(train['text']), list(train['label'])\n",
        "val_queries, val_labels = list(holdout['text'][:val_size]), list(holdout['label'][:val_size])\n",
        "holdout_queries, holdout_labels = list(holdout['text'][val_size:]), list(holdout['label'][val_size:])\n",
        "test_queries, test_labels = list(test['text']), list(test['label'])\n",
        "\n",
        "print(len(train_queries))\n",
        "print(len(val_queries))\n",
        "print(len(holdout_queries))\n",
        "print(len(test_queries))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n",
            "75\n",
            "3667\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amHJD1Jrjsgx"
      },
      "source": [
        "for text, label, name in zip([train_queries, val_queries, test_queries, holdout_queries], \n",
        "                             [train_labels, val_labels, test_labels, holdout_labels],\n",
        "                             ['train', 'val','test', 'holdout']):\n",
        "  pd.DataFrame({'text':text, 'label':label}).to_csv(name+str(n_samples)+'.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30zCaqgOTmtE"
      },
      "source": [
        "## GloVe embedding-based Similarity Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdFbCdMWenVy"
      },
      "source": [
        "# import GloVe embeddings for words\n",
        "# convert the smallest GloVe file: glove.6B.50d.txt into a dictionary\n",
        "# def find_closest_embeddings(embedding):\n",
        "#     return sorted(embeddings_dict.keys(), key=lambda word: spatial.distance.euclidean(embeddings_dict[word], embedding))\n",
        "glove = {}\n",
        "with open(\"glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:], \"float32\")\n",
        "    glove[word] = vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rb_YOmSPO2GP",
        "outputId": "ef39945a-1770-465f-f9e3-861ee30c7f92"
      },
      "source": [
        "# First create a relatively small training set in light of few-shot learning. We collect k samples from each label\n",
        "label_counter = {}\n",
        "n_samples = 20 # This designates the number of each sentence with label i that we have in training\n",
        "train_queries, train_labels = [],[]\n",
        "test_queries, test_labels = [], []\n",
        "for i in range(len(banking2['train'])):\n",
        "  text = banking2['train'][i]['text']\n",
        "  label = banking2['train'][i]['label']\n",
        "  if label not in label_counter:\n",
        "    label_counter.update({label: 1})\n",
        "    train_queries.append(text)\n",
        "    train_labels.append(label)\n",
        "  else:\n",
        "    if label_counter[label] <= n_samples:\n",
        "      train_queries.append(text)\n",
        "      train_labels.append(label)\n",
        "      label_counter[label] += 1\n",
        "    else:\n",
        "      test_queries.append(text)\n",
        "      test_labels.append(label)\n",
        "\n",
        "print(len(train_queries))\n",
        "print(len(test_queries))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "630\n",
            "3371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQJrYd1XoIUr"
      },
      "source": [
        "# pre-processing training queries\n",
        "# remove punctuation & to lowercase\n",
        "test_queries_clean = [re.sub(r'[^\\w\\s]', '', q).lower() for q in test_queries]\n",
        "# convert query into list of words\n",
        "test_queries_clean = [q.split() for q in test_queries_clean]\n",
        "\n",
        "# convert possible labels into list of words\n",
        "label_map_clean = {k:label_map[k].split() for k in label_map}\n",
        "label_words_lst = [l.split() for l in label_map.values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RcQoU_8lVR4",
        "outputId": "d2275270-0a88-49a7-c85d-1b94ca9e665f"
      },
      "source": [
        "# check coverage of words in glove\n",
        "# queries\n",
        "query_word_count, covered_query_word_count = 0, 0\n",
        "for query in test_queries_clean:\n",
        "  for word in query:\n",
        "    query_word_count += 1\n",
        "    if word in glove:\n",
        "      covered_query_word_count += 1\n",
        "\n",
        "# labels\n",
        "label_word_count, covered_label_word_count = 0, 0\n",
        "for label in label_words_lst:\n",
        "  for word in label:\n",
        "    label_word_count += 1\n",
        "    if word in glove:\n",
        "      covered_label_word_count += 1\n",
        "\n",
        "print(\"%.2f percent of the query words are covered by GloVe.\" \n",
        "      % (covered_query_word_count/query_word_count * 100))\n",
        "print(\"%.2f percent of the label words are covered by GloVe.\" \n",
        "      % (covered_label_word_count/label_word_count * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.42 percent of the query words are covered by GloVe.\n",
            "100.00 percent of the label words are covered by GloVe.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M-A2_Bid4oe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41dd8586-4c3d-4140-c5c7-72b329594cf2"
      },
      "source": [
        "# calculate the glove centroid (mean embeddings) for a list of words\n",
        "def mean_glove_emb(word_lst):\n",
        "  n, emb = 0, 0\n",
        "  for word in word_lst:\n",
        "    if word in glove:\n",
        "      n += 1\n",
        "      emb += np.array(glove[word])\n",
        "    if n == 0:\n",
        "      return np.zeros(50)\n",
        "    else:\n",
        "      return (emb/n)\n",
        "\n",
        "# get label embeddings\n",
        "intent_idx_lst = list(set(test_labels))\n",
        "intent_glove_embeddings_lst = [mean_glove_emb(label_map_clean[i]) for \n",
        "                               i in intent_idx_lst]\n",
        "\n",
        "# run an example\n",
        "query1 = test_queries_clean[1]\n",
        "query_embeddings_glove = mean_glove_emb(query1)\n",
        "dot_prod = np.array([query_embeddings_glove @ intent_emb for \n",
        "                     intent_emb in intent_glove_embeddings_lst])\n",
        "top_intents_idx = dot_prod.argsort()[::-1][:5]\n",
        "\n",
        "top_intents_text = [label_map[intent_idx_lst[i]] for i in top_intents_idx]\n",
        "print(\"for the query: \", test_queries[1])\n",
        "print(\"with true label: \", label_map[test_labels[1]])\n",
        "print(\"we get the following nearest neighbors: \")\n",
        "for i in range(len(top_intents_text)):\n",
        "  print(i+1,\". \",top_intents_text[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "for the query:  Have you sent out my card yet?\n",
            "with true label:  card arrival\n",
            "we get the following nearest neighbors: \n",
            "1 .  get disposable virtual card\n",
            "2 .  getting spare card\n",
            "3 .  top up reverted\n",
            "4 .  top up failed\n",
            "5 .  top up by cash or cheque\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWT178o6IHpi",
        "outputId": "8c4d921f-92b3-4044-de35-30adfc65ed8d"
      },
      "source": [
        "# Test in a loop\n",
        "np.random.seed(42)\n",
        "test_ix = np.random.choice(len(test_queries), 500)\n",
        "top_k = 15 # the number of items predict\n",
        "n_correct_glove = 0\n",
        "\n",
        "for ix in test_ix:\n",
        "  query = test_queries_clean[ix]\n",
        "  label = label_map_clean[test_labels[ix]]\n",
        "\n",
        "  # GloVe centroids (before SNN's FF layer) \n",
        "  query_embeddings_glove = mean_glove_emb(query) # ONLY use glove\n",
        "  dot_prod = np.array([query_embeddings_glove @ intent_emb for \n",
        "                       intent_emb in intent_glove_embeddings_lst])\n",
        "  top_intents = dot_prod.argsort()[::-1][:top_k]\n",
        "  top_intents = [intent_idx_lst[i] for i in top_intents]\n",
        "  if test_labels[ix] in top_intents:\n",
        "    n_correct_glove+=1\n",
        "\n",
        "print(\"GloVe: {}\".format(n_correct_glove/len(test_ix)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GloVe: 0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTsey86QuSZF"
      },
      "source": [
        "# Moving onto transformers and more advanced NLP models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II1utiNRBO6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46f30eb0-6afc-4caf-aee9-a5b72c7e1b75"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "\"\"\"\n",
        "The following is from the sentence bert (SBERT) framework\n",
        "https://huggingface.co/sentence-transformers/bert-base-nli-mean-tokens\n",
        "\"\"\"\n",
        "\n",
        "#Mean Pooling - Take attention mask into account for correct averaging\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "#Sentences we want sentence embeddings for\n",
        "query = ['I returned something to a  store but can\\'t see my refund.'] # TRUE INTENT: 'refund not showing up'\n",
        "intent_set = list(label_map.values())\n",
        "\n",
        "#Load AutoModel from huggingface model repository\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\")\n",
        "lm = AutoModel.from_pretrained(\"sentence-transformers/bert-base-nli-mean-tokens\").cuda()\n",
        "\n",
        "#Tokenize sentences and place them on tensor\n",
        "encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "encoded_query['input_ids'] = encoded_query['input_ids'].cuda()\n",
        "encoded_query['attention_mask'] = encoded_query['attention_mask'].cuda()\n",
        "encoded_intents = tokenizer(intent_set, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "encoded_intents['input_ids'] = encoded_intents['input_ids'].cuda()\n",
        "encoded_intents['attention_mask'] = encoded_intents['attention_mask'].cuda()\n",
        "\n",
        "\n",
        "#Compute token embeddings\n",
        "lm.eval()\n",
        "with torch.no_grad():\n",
        "    output_query = lm(**encoded_query)\n",
        "    output_intents = lm(**encoded_intents)\n",
        "\n",
        "#Perform pooling. In this case, mean pooling\n",
        "query_embeddings = mean_pooling(output_query, encoded_query['attention_mask'])\n",
        "intents_embeddings_raw = mean_pooling(output_intents, encoded_intents['attention_mask'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at sentence-transformers/bert-base-nli-mean-tokens were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfOqiIPaHVFg",
        "outputId": "91ffe7df-6bcc-418f-f56c-5e3cf176d4a6"
      },
      "source": [
        "# Now take the dot product to find out which ones are closest\n",
        "# We see that the true intent is the third one. But considering this is a baseline model this isn't unexpected \n",
        "top_intents = torch.topk(torch.inner(query_embeddings, intents_embeddings_raw), k = 5).indices.squeeze()\n",
        "for i in range(len(top_intents)):\n",
        "  print(i+1,\". \",intent_set[top_intents[i].item()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 .  balance not updated after bank transfer\n",
            "2 .  balance not updated after cheque or cash deposit\n",
            "3 .  refund not showing up\n",
            "4 .  declined card payment\n",
            "5 .  lost or stolen phone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ceDvO4m2Gzy"
      },
      "source": [
        "# Plain ZSL (full hypothesis set) implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcCW7MVS3p8_"
      },
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",model=\"facebook/bart-large-mnli\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg8cupzJ3grs",
        "outputId": "8bc38d83-bbbd-495b-af02-05f7170005eb"
      },
      "source": [
        "for i in range(10):\n",
        "  scores = classifier(test_queries[i], intent_set)\n",
        "  print(scores['labels'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cash withdrawal charge\n",
            "pending top up\n",
            "topping up by card\n",
            "pending top up\n",
            "balance not updated after cheque or cash deposit\n",
            "activate my card\n",
            "refund not showing up\n",
            "getting spare card\n",
            "extra charge on statement\n",
            "balance not updated after cheque or cash deposit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG6vJjdUJXMm"
      },
      "source": [
        "# Siamese neural network implementation\n",
        "The basic idea is that we train a siamese neural network based on the triplet loss function for few-shot learning. In the triplet loss framework we provide a query that's of the same class and another query that is not of the same class.\n",
        "\n",
        "After training the model to distinguish which query is of the same class and which is not, we can use the network for unseen queries. We can then feed in the new query along with all of the label centroids to determine which label centroid is closest to the new query. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e-PgiClVeQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c599a8d-e5e3-469f-9354-096e1a78e8f0"
      },
      "source": [
        "# Next embed the training queries and create centroids based on the train\n",
        "\n",
        "encoded_query = tokenizer(train_queries,return_token_type_ids=False, padding=True,  max_length=128, return_tensors='pt')\n",
        "train_input_ids = encoded_query['input_ids'].cuda()\n",
        "train_attn_mask = encoded_query['attention_mask'].cuda()\n",
        "with torch.no_grad():\n",
        "    output_query = lm(input_ids = train_input_ids, \n",
        "                         attention_mask = train_attn_mask) #unpack arguments \n",
        "\n",
        "query_embeddings = mean_pooling(output_query, train_attn_mask)\n",
        "\n",
        "print(query_embeddings.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([600, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAhbNtQJWe3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7f88f9-40da-4793-bb4b-fb97663e1f94"
      },
      "source": [
        "intent_centroids = {}\n",
        "intent_centroids_lm = torch.zeros(intents_embeddings_raw.shape).cuda()\n",
        "\n",
        "# train_labels = torch.tensor(train_labels)\n",
        "# test_labels = torch.tensor(test_labels)\n",
        "\n",
        "# centroids = torch.zeros((len(set(train_labels)), query_embeddings.shape[1]))\n",
        "i=0\n",
        "for label in set(train_labels):\n",
        "  ix = np.where(np.array(train_labels) == label)[0]\n",
        "  intent_centroids[label] = torch.mean(query_embeddings[ix,:], dim = 0)\n",
        "  intent_centroids_lm[i,:] = torch.mean(query_embeddings[ix,:], dim = 0)\n",
        "  i+=1\n",
        "\n",
        "print(\"Created {} centroids based on query embeddings and label groups.\".format(n_classes))\n",
        "print(intent_centroids.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created 30 centroids based on query embeddings and label groups.\n",
            "dict_keys([0, 1, 5, 6, 11, 17, 19, 23, 25, 31, 32, 34, 36, 37, 39, 42, 43, 47, 49, 51, 52, 55, 58, 59, 61, 62, 63, 64, 69, 72])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9OouLPpHtMh"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self, lm):\n",
        "      super(SiameseNet, self).__init__()\n",
        "      torch.manual_seed(6864)\n",
        "      self.lm = lm\n",
        "      self.embedding_dim = 768\n",
        "      self.output_size = 128\n",
        "\n",
        "      self.lin = nn.Linear(self.embedding_dim, 512)\n",
        "      self.lin1 = nn.Linear(512, 256)\n",
        "      self.out = nn.Linear(256, self.output_size)\n",
        "      self.dropout = nn.Dropout(0.02)\n",
        "\n",
        "    def freeze_lm(self): # freeze the SBERT model such that we only train the classifier \n",
        "      for param in self.lm.parameters():\n",
        "        param.requires_grad = False\n",
        "    def unfreeze_lm(self):\n",
        "      for param in self.lm.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    def FF(self, embeddings): # Feed forward embedding \n",
        "      x = F.relu(self.lin(embeddings))\n",
        "      x = self.dropout(x)\n",
        "      x = F.relu(self.lin1(x))\n",
        "      x = self.out(x)\n",
        "      return x\n",
        "\n",
        "    def forward_one(self, encoded_query): # define the same forward function for the embeddings to produce embedding representation\n",
        "      output = self.lm(**encoded_query)\n",
        "      embeddings = mean_pooling(output, encoded_query['attention_mask']) # pool -> (batch size, hidden_size)\n",
        "      x = self.FF(embeddings)\n",
        "      return x\n",
        "\n",
        "    def forward(self, anc_encoded, pos_encoded, neg_encoded): # takes in anchor, positive, and negative\n",
        "      anc_emb = self.forward_one(anc_encoded) # pool -> (batch size, 32)\n",
        "      pos_emb = self.forward_one(pos_encoded)\n",
        "      neg_emb = self.forward_one(neg_encoded)\n",
        "      return anc_emb, pos_emb, neg_emb\n",
        "\n",
        "\n",
        "# define a loss function\n",
        "from torch.nn.modules.distance import PairwiseDistance\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, eps): # eps is some margin \n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "        self.dist_fcn = PairwiseDistance(p=2)\n",
        "\n",
        "    def forward(self, anc_emb, pos_emb, neg_emb):\n",
        "        pos_dist = self.dist_fcn(anc_emb, pos_emb)\n",
        "        neg_dist = self.dist_fcn(anc_emb, neg_emb)\n",
        "\n",
        "        hinge_dist = torch.clamp(self.eps + pos_dist - neg_dist, min=0.0)\n",
        "        loss = torch.mean(hinge_dist) # take the average distance in the batch to be the loss  \n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CJIklTiF_HZ"
      },
      "source": [
        "# Triplet selection\n",
        "Given $x_{i}^{a}$ we want to select positive anchor (within a batch) such that $x_{i}^{p} = argmax||f(x_{i}^{a})-f(x_{i}^{p})||_{2}^{2}$ (it looks far from anchor, but is actually the same class) and similarly we want $x_{i}^{n} = argmin||f(x_{i}^{a})-f(x_{i}^{n})||_{2}^{2}$ (it looks close together but is actually of a different class). \n",
        "\n",
        "We can also consider \"semi-hard\" examples which have the property that $||f(x_{i}^{a})-f(x_{i}^{p})||_{2}^{2} \\leq ||f(x_{i}^{a})-f(x_{i}^{n})||_{2}^{2}$. \n",
        "\n",
        "Lastly, the Facenet paper recommends \"Instead of picking the hardest positive, we use all anchor-positive pairs in a mini-batch while still selecting the hard negatives.\" In similar vein, we can include all anchor-centroid pairs so that all labels eventually learn that they belong with a certain centroid.\n",
        "\n",
        "Ultimately, we have to make sure that we have some positive number of examples for each class. Because we are treating this as a semi-supervised problem, we're going to assume that we have limited labels (e.g. 20 labels of each class) and will instead use random sampling to create batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLFPOo1QfLu5"
      },
      "source": [
        "# Wrap the batch generation into a function \n",
        "def generate_batch(model, train_input_ids, train_attn_mask, train_labels, centroids, n_pos, random_state):\n",
        "  \"\"\"\n",
        "  Model: the Siamese net model that will be used to generate embeddings\n",
        "  train_input_ids: ALL tokenized input ids across the training set\n",
        "  train_attention mask: ALL tokenized attention masks across the training set\n",
        "  train_labels: ALL labels across the training set\n",
        "  centroids: A dictionary that maps {label: centroid embedding}  \n",
        "  n_pos: The number of examples to draw from each class in train_labels\n",
        "  random_state: The seet to be set \n",
        "  \"\"\"\n",
        "\n",
        "  batch_ix = np.array([])\n",
        "  np.random.seed(random_state)\n",
        "  label_set = list(set(train_labels))\n",
        "  for label in label_set:\n",
        "    label_ix = np.where(np.array(label)==np.array(train_labels))[0]\n",
        "    label_ix = np.random.choice(label_ix,size=n_pos, replace = False) \n",
        "    batch_ix = np.concatenate([batch_ix, label_ix]).astype(np.int32)\n",
        "  batch_size = len(batch_ix)\n",
        "  batch_anc_enc = {'input_ids': train_input_ids[batch_ix], 'attention_mask': train_attn_mask[batch_ix]}\n",
        "  # Embed everything in the sample and obtain the distance matrix\n",
        "  embeddings = model.forward_one(batch_anc_enc)\n",
        "  emb_dists = torch.cdist(embeddings,embeddings, p=2)\n",
        "  # find the indices of emb_dists with the respective max (if same class) or min (if different class) for the distance\n",
        "  pos_samples = torch.zeros((batch_size)).long()\n",
        "  neg_samples = torch.zeros((batch_size)).long()\n",
        "  # Get the embedding of the same label centroid as well as some embedding of a (random) different label centroid\n",
        "  # Unlike pos/neg samples we'll just create this directly (not through input_ids and attention_mask)\n",
        "  emb_shape = centroids[label_set[0]].shape[0] # 768 is the shape of each centroid \n",
        "  pos_centroid_samples = torch.zeros((batch_size,emb_shape))\n",
        "  neg_centroid_samples = torch.zeros((batch_size,emb_shape))\n",
        "\n",
        "  batch_labels = np.array(train_labels)[batch_ix]\n",
        "  np.random.seed(random_state)\n",
        "  for i in range(batch_size): # just do brute-force over all selected samples for each label - it's a small matrix, otherwise it's too difficult to deal with indices\n",
        "    lab = batch_labels[i]\n",
        "    pos_ix = np.where(lab == batch_labels)[0]\n",
        "    pos_ix = np.setdiff1d(pos_ix, i) \n",
        "    neg_ix = np.where(lab != batch_labels)[0]\n",
        "    pos_dists = emb_dists[i,pos_ix]\n",
        "    neg_dists = emb_dists[i,neg_ix]\n",
        "    pos_samples[i] = pos_ix[torch.argmax(pos_dists)] # Hard-positive\n",
        "    neg_samples[i] = neg_ix[torch.argmin(neg_dists)] # Hard-negative\n",
        "    pos_centroid_samples[i] = centroids[lab] # Centroid-positive\n",
        "    diff_labels = [x for x in label_set if x != lab] # Randomly pick a different centroid to designate as a negative \n",
        "    neg_centroid_samples[i] = centroids[ np.random.choice(diff_labels, size=1, replace = False)[0] ] # Centroid-negative\n",
        "\n",
        "  # now generate a batch-based set of (anchor, hard-positive, hard-negative) triplets\n",
        "  pos_input_ids, pos_attention_mask = batch_anc_enc['input_ids'][pos_samples], batch_anc_enc['attention_mask'][pos_samples]\n",
        "  neg_input_ids, neg_attention_mask = batch_anc_enc['input_ids'][neg_samples], batch_anc_enc['attention_mask'][neg_samples]\n",
        "\n",
        "  batch_pos_enc = {'input_ids': pos_input_ids, 'attention_mask': pos_attention_mask}\n",
        "  batch_neg_enc = {'input_ids': neg_input_ids, 'attention_mask': neg_attention_mask}\n",
        "\n",
        "  return batch_anc_enc, batch_pos_enc, batch_neg_enc, pos_centroid_samples, neg_centroid_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdKiliy3uV7D"
      },
      "source": [
        "# Hyper-parameters:\n",
        "import transformers\n",
        "\n",
        "num_epochs = 40\n",
        "num_batches = 10\n",
        "learning_rate = 5e-4\n",
        "weight_decay = 1e-7\n",
        "optimizer_eps = 1e-6\n",
        "triplet_eps = 6\n",
        "n_pos = 5\n",
        "warmup_rate = 0.05\n",
        "ques_max_length = 64\n",
        "max_grad_norm = 5\n",
        "ctx_max_length = 448\n",
        "batch_size = n_pos*n_classes*2 # (x2 because we have both hard p/n and centroid p/n)\n",
        "\n",
        "# Calculating the number of warmup steps\n",
        "num_training_cases = num_batches*n_pos*n_classes\n",
        "t_total = (num_training_cases // batch_size + 1) * num_epochs\n",
        "ext_warmup_steps = int(warmup_rate * t_total)\n",
        "\n",
        "# Create model \n",
        "Siamese = SiameseNet(lm).cuda()\n",
        "Siamese.freeze_lm()\n",
        "# Siamese.unfreeze_lm()\n",
        "\n",
        "loss_fn = TripletLoss(eps = triplet_eps)\n",
        "\n",
        "# Initializing an AdamW optimizer\n",
        "learning_rate = 3e-4\n",
        "ext_optim = torch.optim.Adam(Siamese.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9RKNd9GfTtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40996973-37fc-44e1-dcb9-6708f34772e8"
      },
      "source": [
        "# Important to make sure all inputs (except train_labels) is on the same device \n",
        "Siamese.train()\n",
        "\n",
        "batch_loop = 2 # number of times we pass through each batch \n",
        "anneal_epsilon = True\n",
        "\n",
        "torch.manual_seed(6864)\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in range(num_batches):\n",
        "\n",
        "    # Zero out gradient\n",
        "    Siamese.zero_grad() \n",
        "\n",
        "    # Generate batch\n",
        "    batch_anc_enc, batch_pos_enc, batch_neg_enc, pos_centroid, neg_centroid = generate_batch(Siamese, train_input_ids, train_attn_mask, train_labels, \n",
        "                                                                                             intent_centroids, n_pos, batch*epoch)\n",
        "\n",
        "    for _ in range(batch_loop):\n",
        "      # Encode anc/pos/neg\n",
        "      anc_emb, pos_emb, neg_emb = Siamese(batch_anc_enc, batch_pos_enc, batch_neg_enc)\n",
        "\n",
        "      # Embed centroids\n",
        "      pos_centroid_emb = Siamese.FF(pos_centroid.cuda())\n",
        "      neg_centroid_emb = Siamese.FF(neg_centroid.cuda())\n",
        "\n",
        "      # compute the loss \n",
        "      main_loss = loss_fn(anc_emb, pos_emb, neg_emb)\n",
        "      # print(\"Hard Pos/Neg Loss: {}\".format(main_loss))\n",
        "\n",
        "      centroid_loss = loss_fn(anc_emb, pos_centroid_emb, neg_centroid_emb)\n",
        "      # print(\"Centroid Pos/Neg Loss: {}\".format(centroid_loss))\n",
        "\n",
        "      total_loss = main_loss + centroid_loss # concatenate the loss \n",
        "\n",
        "      total_loss.backward()\n",
        "      # torch.nn.utils.clip_grad_norm_(Siamese.parameters(), max_grad_norm)\n",
        "      ext_optim.step()\n",
        "      # ext_sche.step() # Update learning rate for better convergence\n",
        "    \n",
        "\n",
        "    if (epoch % 2 == 0) & (batch == num_batches-1):\n",
        "      print(\"Epoch {} batch {} total loss: {}\".format(epoch, batch, total_loss))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 batch 9 total loss: 8.630136489868164\n",
            "Epoch 2 batch 9 total loss: 7.261341094970703\n",
            "Epoch 4 batch 9 total loss: 5.1447248458862305\n",
            "Epoch 6 batch 9 total loss: 3.697981834411621\n",
            "Epoch 8 batch 9 total loss: 4.030923843383789\n",
            "Epoch 10 batch 9 total loss: 1.9100823402404785\n",
            "Epoch 12 batch 9 total loss: 1.3651505708694458\n",
            "Epoch 14 batch 9 total loss: 0.5625714063644409\n",
            "Epoch 16 batch 9 total loss: 0.32262465357780457\n",
            "Epoch 18 batch 9 total loss: 0.6174914240837097\n",
            "Epoch 20 batch 9 total loss: 0.2624626159667969\n",
            "Epoch 22 batch 9 total loss: 0.17559868097305298\n",
            "Epoch 24 batch 9 total loss: 0.23426397144794464\n",
            "Epoch 26 batch 9 total loss: 0.09838125854730606\n",
            "Epoch 28 batch 9 total loss: 0.029896901920437813\n",
            "Epoch 30 batch 9 total loss: 0.013035736046731472\n",
            "Epoch 32 batch 9 total loss: 0.08113095909357071\n",
            "Epoch 34 batch 9 total loss: 0.03752696514129639\n",
            "Epoch 36 batch 9 total loss: 0.05352046340703964\n",
            "Epoch 38 batch 9 total loss: 0.03151318430900574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGZXYdyn8gJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a432dab4-051e-4265-a0fa-bf60755a6f92"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# evaluate the model\n",
        "Siamese.eval()\n",
        "\n",
        "# Embed all labels with the trained network \n",
        "intents_embeddings = torch.zeros((n_classes, Siamese.output_size)).cuda()\n",
        "intent_set = list(set(train_labels))\n",
        "for i in range(len(intent_set)):\n",
        "  lab = intent_set[i]\n",
        "  intents_embeddings[i,:] = Siamese.FF(intent_centroids[lab].cuda())\n",
        "\n",
        "\n",
        "# Test in a loop \n",
        "\n",
        "top_k = 1 # the number of items predict\n",
        "n_correct_SNN = 0\n",
        "\n",
        "for ix in range(len(val_queries)):\n",
        "  query = val_queries[ix]\n",
        "  label = label_map[val_labels[ix]]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = Siamese.forward_one(encoded_query)\n",
        "  top_intents = torch.topk(torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), k = top_k, largest = False).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_set = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_set.append(label_map[label_ix])\n",
        "  if label in top_intents_set:\n",
        "    n_correct_SNN+=1\n",
        "\n",
        "print(\"SNN: {}\".format(n_correct_SNN/len(val_queries)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNN: 0.9333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92oKMChWeEo"
      },
      "source": [
        "Evaluate SNN on the testing set below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOK8a4rX8AqW"
      },
      "source": [
        "# # Say we have a new query for which we want to find closeby centroids\n",
        "# i = 300\n",
        "# query = test_queries[i]\n",
        "# print(\"Test Query: \",query)\n",
        "# print(\"Test Label: \",label_map[test_labels[i]])\n",
        "\n",
        "# # Embed the query\n",
        "# encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "# encoded_query.to(device)\n",
        "# query_embeddings = Siamese.forward_one(encoded_query)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEdHf6aiFh1D"
      },
      "source": [
        "# Test in a loop \n",
        "\n",
        "top_k = 1 # the number of items predict\n",
        "n_correct_SNN = 0\n",
        "n_correct_CentNN = 0\n",
        "n_correct_SBERT = 0\n",
        "\n",
        "for ix in range(len(test_queries)):\n",
        "  query = test_queries[ix]\n",
        "  label = label_map[test_labels[ix]]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = Siamese.forward_one(encoded_query)\n",
        "  top_intents = torch.topk(torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), k = top_k, largest = False).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_set = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_set.append(label_map[label_ix])\n",
        "  if label in top_intents_set:\n",
        "    n_correct_SNN+=1\n",
        "\n",
        "  # With unsupervised SBERT embeddings: get the embedding label corresponding to the largest dot product \n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "\n",
        "\n",
        "  top_intents = torch.topk(torch.inner(query_embeddings_LM, intents_embeddings_raw), k = top_k).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_set = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_set.append(label_map[label_ix])\n",
        "  if label in top_intents_set:\n",
        "    n_correct_SBERT+=1\n",
        "\n",
        "  # With language model (LM) centroids (before SNN's FF layer) \n",
        "  top_intents_set = []\n",
        "  top_intents = torch.topk(torch.inner(query_embeddings_LM, intent_centroids_lm), k = top_k).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_set.append(label_map[label_ix])\n",
        "  if label in top_intents_set:\n",
        "    n_correct_CentNN+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_NUBnDFUTVa",
        "outputId": "202768d4-fce7-403e-cb0e-9615151c3070"
      },
      "source": [
        "print(\"Unsupervised Methods\")\n",
        "print(\"SBERT: {}\".format(n_correct_SBERT/len(test_queries)))\n",
        "\n",
        "print(\"Semisupervised Methods\")\n",
        "print(\"CentNN: {}\".format(n_correct_CentNN/len(test_queries)))\n",
        "print(\"SNN: {}\".format(n_correct_SNN/len(test_queries)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unsupervised Methods\n",
            "SBERT: 0.486\n",
            "Semisupervised Methods\n",
            "CentNN: 0.54\n",
            "SNN: 0.861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYAHo_UGz8m"
      },
      "source": [
        "# Pseudo SNN\n",
        "\n",
        "In this modification, instead of using the Siamese structure, we use a different feed forward layer to embed the centroids "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QdBxsQQGzIz"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PseudoSiameseNet(nn.Module):\n",
        "    def __init__(self, lm):\n",
        "      super(PseudoSiameseNet, self).__init__()\n",
        "      torch.manual_seed(6864)\n",
        "      self.lm = lm\n",
        "      self.embedding_dim = 768\n",
        "      self.output_size = 128\n",
        "\n",
        "      self.FF_lins = nn.ModuleList([nn.Linear(self.embedding_dim, 512),\n",
        "                                    nn.Linear(512, 256)])\n",
        "      self.FF_out = nn.Linear(256, self.output_size)\n",
        "\n",
        "      self.FF_cent_lins = nn.ModuleList([nn.Linear(self.embedding_dim, 512),\n",
        "                                    nn.Linear(512, 256)])\n",
        "      self.FF_cent_out = nn.Linear(256, self.output_size)\n",
        "\n",
        "      self.dropout = nn.Dropout(0.02)\n",
        "\n",
        "    def freeze_lm(self): # freeze the SBERT model such that we only train the classifier \n",
        "      for param in self.lm.parameters():\n",
        "        param.requires_grad = False\n",
        "    def unfreeze_lm(self):\n",
        "      for param in self.lm.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    def FF(self, x): # Feed forward embedding \n",
        "      for lin in self.FF_lins:\n",
        "        x = F.relu(lin(x))\n",
        "        x = self.dropout(x)\n",
        "      x = self.FF_out(x)\n",
        "      return x\n",
        "\n",
        "    def FF_cent(self, x): # Feed forward embedding \n",
        "      for lin in self.FF_cent_lins:\n",
        "        x = F.relu(lin(x))\n",
        "        x = self.dropout(x)\n",
        "      x = self.FF_cent_out(x)\n",
        "      return x\n",
        "\n",
        "    def forward_one(self, encoded_query): # define the same forward function for the embeddings to produce embedding representation\n",
        "      output = self.lm(**encoded_query)\n",
        "      embeddings = mean_pooling(output, encoded_query['attention_mask']) # pool -> (batch size, hidden_size)\n",
        "      x = self.FF(embeddings)\n",
        "      return x\n",
        "\n",
        "    def forward(self, anc_encoded, pos_encoded, neg_encoded): # takes in anchor, positive, and negative\n",
        "      anc_emb = self.forward_one(anc_encoded) # pool -> (batch size, 32)\n",
        "      pos_emb = self.forward_one(pos_encoded)\n",
        "      neg_emb = self.forward_one(neg_encoded)\n",
        "      return anc_emb, pos_emb, neg_emb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQuQDF_wGzi3"
      },
      "source": [
        "# Hyper-parameters:\n",
        "import transformers\n",
        "\n",
        "num_epochs = 40\n",
        "num_batches = 10\n",
        "learning_rate = 3e-4\n",
        "weight_decay = 1e-8\n",
        "optimizer_eps = 1e-6\n",
        "triplet_eps = 5\n",
        "n_pos = 5\n",
        "warmup_rate = 0.05\n",
        "ques_max_length = 64\n",
        "max_grad_norm = 5\n",
        "ctx_max_length = 448\n",
        "batch_size = n_pos*n_classes*2 # (x2 because we have both hard p/n and centroid p/n)\n",
        "\n",
        "# Calculating the number of warmup steps\n",
        "num_training_cases = num_batches*n_pos*n_classes\n",
        "t_total = (num_training_cases // batch_size + 1) * num_epochs\n",
        "ext_warmup_steps = int(warmup_rate * t_total)\n",
        "\n",
        "# Create model \n",
        "PseudoSiamese = PseudoSiameseNet(lm).cuda()\n",
        "PseudoSiamese.freeze_lm()\n",
        "# Siamese.unfreeze_lm()\n",
        "\n",
        "loss_fn = TripletLoss(eps = triplet_eps)\n",
        "\n",
        "# stick with Adam optimizer \n",
        "learning_rate = 3e-4\n",
        "ext_optim = torch.optim.Adam(PseudoSiamese.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Initializing an AdamW optimizer\n",
        "# ext_optim = torch.optim.AdamW(PseudoSiamese.parameters(), lr=learning_rate,\n",
        "#                               eps=optimizer_eps, weight_decay=weight_decay)\n",
        "\n",
        "# # Initializing the learning rate scheduler [details are in the BERT paper]\n",
        "# ext_sche = transformers.get_linear_schedule_with_warmup(\n",
        "#     ext_optim, num_warmup_steps=ext_warmup_steps, num_training_steps=t_total\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvUVQMQoKQUr",
        "outputId": "15be6d45-3cef-4690-b3a3-f13eeaf4cbef"
      },
      "source": [
        "# Important to make sure all inputs (except train_labels) is on the same device \n",
        "PseudoSiamese.train()\n",
        "\n",
        "batch_loop = 2 # number of times we pass through each batch \n",
        "\n",
        "torch.manual_seed(6864)\n",
        "for epoch in range(num_epochs):\n",
        "  for batch in range(num_batches):\n",
        "\n",
        "    # Zero out gradient\n",
        "    PseudoSiamese.zero_grad() \n",
        "\n",
        "    # Generate batch\n",
        "    batch_anc_enc, batch_pos_enc, batch_neg_enc, pos_centroid, neg_centroid = generate_batch(PseudoSiamese, train_input_ids, train_attn_mask, train_labels, \n",
        "                                                                                             intent_centroids, n_pos, batch*epoch)\n",
        "\n",
        "    for _ in range(batch_loop):\n",
        "      # Encode anc/pos/neg\n",
        "      anc_emb, pos_emb, neg_emb = PseudoSiamese(batch_anc_enc, batch_pos_enc, batch_neg_enc)\n",
        "\n",
        "      # Embed centroids\n",
        "      pos_centroid_emb = PseudoSiamese.FF_cent(pos_centroid.cuda())\n",
        "      neg_centroid_emb = PseudoSiamese.FF_cent(neg_centroid.cuda())\n",
        "\n",
        "      # compute the loss \n",
        "      main_loss = loss_fn(anc_emb, pos_emb, neg_emb)\n",
        "      # print(\"Hard Pos/Neg Loss: {}\".format(main_loss))\n",
        "\n",
        "      centroid_loss = loss_fn(anc_emb, pos_centroid_emb, neg_centroid_emb)\n",
        "      # print(\"Centroid Pos/Neg Loss: {}\".format(centroid_loss))\n",
        "\n",
        "      total_loss = main_loss + centroid_loss # concatenate the loss \n",
        "\n",
        "      total_loss.backward()\n",
        "      ext_optim.step()\n",
        "      # ext_sche.step() # Update learning rate for better convergence\n",
        "    \n",
        "\n",
        "    if (epoch % 2 == 0) & (batch == num_batches-1):\n",
        "      print(\"Epoch {} batch {} total loss: {}\".format(epoch, batch, total_loss))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 batch 9 total loss: 8.720535278320312\n",
            "Epoch 2 batch 9 total loss: 7.181765079498291\n",
            "Epoch 4 batch 9 total loss: 5.36004638671875\n",
            "Epoch 6 batch 9 total loss: 4.013286590576172\n",
            "Epoch 8 batch 9 total loss: 3.0403995513916016\n",
            "Epoch 10 batch 9 total loss: 1.9707510471343994\n",
            "Epoch 12 batch 9 total loss: 1.5759813785552979\n",
            "Epoch 14 batch 9 total loss: 0.8636195063591003\n",
            "Epoch 16 batch 9 total loss: 0.41083788871765137\n",
            "Epoch 18 batch 9 total loss: 0.22334222495555878\n",
            "Epoch 20 batch 9 total loss: 0.29334768652915955\n",
            "Epoch 22 batch 9 total loss: 0.18339276313781738\n",
            "Epoch 24 batch 9 total loss: 0.2313760370016098\n",
            "Epoch 26 batch 9 total loss: 0.0500829704105854\n",
            "Epoch 28 batch 9 total loss: 0.050625551491975784\n",
            "Epoch 30 batch 9 total loss: 0.08427371084690094\n",
            "Epoch 32 batch 9 total loss: 0.03359883651137352\n",
            "Epoch 34 batch 9 total loss: 0.1361265629529953\n",
            "Epoch 36 batch 9 total loss: 0.02278233878314495\n",
            "Epoch 38 batch 9 total loss: 0.012556979432702065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi4ujhtDZdUA"
      },
      "source": [
        "Test on validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leZiHGxTZEKx",
        "outputId": "cec5d536-b156-497d-c349-17354066ac45"
      },
      "source": [
        "# Test in a loop \n",
        "top_k = 1 # the number of items predict\n",
        "n_correct_SNN = 0\n",
        "\n",
        "# evaluate the model\n",
        "PseudoSiamese.eval()\n",
        "\n",
        "# Embed all labels with the trained network \n",
        "intents_embeddings = torch.zeros((n_classes, PseudoSiamese.output_size)).cuda()\n",
        "intent_set = list(set(train_labels))\n",
        "for i in range(len(intent_set)):\n",
        "  lab = intent_set[i]\n",
        "  intents_embeddings[i,:] = PseudoSiamese.FF_cent(intent_centroids[lab].cuda())\n",
        "\n",
        "for ix in range(len(val_queries)):\n",
        "  query = val_queries[ix]\n",
        "  label = label_map[val_labels[ix]]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  top_intents = torch.topk(torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), k = top_k, largest = False).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_set = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_set.append(label_map[label_ix])\n",
        "  if label in top_intents_set:\n",
        "    n_correct_SNN+=1\n",
        "\n",
        "print(\"SNN: {}\".format(n_correct_SNN/len(val_queries)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SNN: 0.9066666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_01objUvZfdL"
      },
      "source": [
        "Test on testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb8PyMP0NqMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dec92e75-e605-4dc8-de86-f879b9df4730"
      },
      "source": [
        "# Test in a loop \n",
        "top_k = 1 # the number of items predict\n",
        "n_correct_SNN = 0\n",
        "\n",
        "# evaluate the model\n",
        "PseudoSiamese.eval()\n",
        "\n",
        "# Embed all labels with the trained network \n",
        "intents_embeddings = torch.zeros((n_classes, PseudoSiamese.output_size)).cuda()\n",
        "intent_set = list(set(train_labels))\n",
        "for i in range(len(intent_set)):\n",
        "  lab = intent_set[i]\n",
        "  intents_embeddings[i,:] = PseudoSiamese.FF_cent(intent_centroids[lab].cuda())\n",
        "\n",
        "for ix in range(len(test_queries)):\n",
        "  query = test_queries[ix]\n",
        "  label = label_map[test_labels[ix]]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  top_intents = torch.topk(torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), k = top_k, largest = False).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_set = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_set.append(label_map[label_ix])\n",
        "  if label in top_intents_set:\n",
        "    n_correct_SNN+=1\n",
        "\n",
        "n_correct_SNN/len(test_queries)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5YsoIm7XW9K"
      },
      "source": [
        "### Create TSNE Visualization on the training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfW5ZehKNNzU"
      },
      "source": [
        "# TSNE visualization \n",
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "\n",
        "# TRAINING DATA\n",
        "np.random.seed(12345)\n",
        "a = intent_set[:10]\n",
        "emb_sample_ix = [i for i in range(len(train_labels)) if train_labels[i] in a]\n",
        "emb_sample_ix = np.random.choice(emb_sample_ix, size = 100, replace = False)\n",
        "\n",
        "SBERT_embedding = np.zeros((len(emb_sample_ix), 768))\n",
        "SNN_embedding = np.zeros((len(emb_sample_ix), PseudoSiamese.output_size))\n",
        "emb_lab = []\n",
        "\n",
        "for i in range(len(emb_sample_ix)):\n",
        "  ix = emb_sample_ix[i]\n",
        "  query = train_queries[ix]\n",
        "  label = train_labels[ix]\n",
        "  emb_lab.append(label)\n",
        "\n",
        "  # embed with SBERT \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "  SBERT_embedding[i,:] = query_embeddings_LM.detach().cpu().numpy()\n",
        "\n",
        "  # embed with PSNN\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  SNN_embedding[i,:] = query_embeddings_SNN.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "emb_lab = [label_map[x] for x in emb_lab]\n",
        "lm_emb = TSNE(n_components=2).fit_transform(SBERT_embedding)\n",
        "snn_emb = TSNE(n_components=2).fit_transform(SNN_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "sJ7Uo8kaNlZS",
        "outputId": "2f987a26-7a7a-477a-c3ce-5e01ddf56951"
      },
      "source": [
        "sns.scatterplot(lm_emb[:,0], lm_emb[:,1], hue = emb_lab,)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.xlabel(\"Embedding Dim 1\")\n",
        "plt.ylabel(\"Embedding Dim 2\")\n",
        "plt.title(\"SBERT Query Embeddings - Training\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-152-a6b9362c3141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_emb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_lab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox_to_anchor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborderaxespad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Embedding Dim 1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Embedding Dim 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SBERT Query Embeddings - Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wVVfqHn5m5Pb0CIUAAqamUIEUFKYqCKFLsK+7a3dV1VxTLuqzlt80tYlnFVdG1Ia5r31VRULBSpIP0EgikJzfJbTNzfn9cciHJTb8pF+b5fK4yJzPnnCn3vWfe857vKwkhMDAwMDAIX+TO7oCBgYGBQdswDLmBgYFBmGMYcgMDA4MwxzDkBgYGBmGOYcgNDAwMwhxTZzSamJgo0tLSOqNpAwMDg7Bl3bp1RUKIpLrlnWLI09LSWLt2bWc0bWBgYBC2SJJ0IFi54VoxMDAwCHMMQ25gYGAQ5hiG3MDAwCDMMQy5gYGBQZhjGHIDAwODMKdTolYMwgtd1zl27BgFBQVYLBZ69OhBbGxsu7Tlch3C6dyKplUTETGQqKihSJIx3jAwaAzDkBs0yYEDB3jllVfQNA2A5ORkrrjiCuLi4kLaTnX1QTZuup7q6j0ASJKJnOwlxMePCWk7BganGsZQx6BRPB4Py5cvDxhxgIKCAvLy8kLeVkXFhoARBxBCZc/ev6CqlSFvy8DgVMIYkRs0is/no6ysrF55ZWXLjKvX66WkpASA+Ph4LBZLkH2K6pW53YfQNDcmU2SL2jMwOJ0wDLlBozgcDoYNG8bq1atrlffo0aPZdZSVlbF8+XK2bNkCQGZmJpMmTarnZ4+Kzqx3bEqPy7BYElrRcwOD0wfDtWLQKLIsM2LECHJzc1EUhcjISGbPnk3Pnj2bXcfOnTsDRhxg8+bN7Nq1q95+0VGZZGQ8idXaA1m20rvXz0hJuQxJklrV96rq/Rw5sox9+5+ipPQbVLW6VfUYGHR1jBG5QZPExcUxdepUxo0bh8lkIjKyZW6OHTt2BC3Lzc2tVaYoNrolX0BszCiE8GK1JiNJSqv67HIdYuPGn+Fy7Q+UpQ/9G927z2hVfQYGXRljRG7QLBRFITY2tsVGHPwiac0pq8FqTcBm69FqIw7gdG6tZcQBdu3+PR5PYavrNDDoqhiG3KDdGTp0KMnJyYHt5ORkhgwZ0q5tarqrXpmqVqALX7u2a2DQGRiuldMUVVUpKCigtLSUiIgIunXrht1ub5e2EhMTueaaaygs9I+Gk5KSiIqKape2aoiMGIQkWRDCGyhLTf0JNmu3dm3XwKAzMAz5acqPP/7IW2+9hRACgJEjRzJ58mRsNlu7tBcVFdXuxvtkIiOHMGzYy+zb9zgu10FSUi6nR/eZbXLXGBh0VQxDfhpSVlbGBx98EDDiAGvXriUrK4vevXt3Ys/8eL3FFJes4ujRd4iMHEL3bhcTFTW4RXVIkkRcbC7RWc+haW4sltCuQjUw6EoYhvw0xO1243LV9yG3dJFPeyCE4PCRN9i7968AlJSsIj//LUaOeBOHo2+L61MUO4rSPi4jA4OugjHZeRoSHR1N9+7da5XJskxCQucvvHG7j7B//z9qlfl8JTgr64cwGhgY+DEM+WmIw+HgkksuISUlBYDIyEguu+wykpLq5XTtMrR0SZCmVeP1FtdyHxl0USoLYNdy2PAaHPgGvFWd3aOww3CtnKZ0796da665BqfTic1mIzo6urO7BIDNlkJa2q3s3fuXQJnZHE9kZPN85EIIysrWsHff345Pcs6lR/fZ2O3NX4lq0IG4SuHj+2DzshNl0/8OI+ZBK1f0no6EzJBL/nCAtcBhIcT0UNVr0H7Y7fZ2CzlsLZIkkdLjMuy2VPKPvktU1GC6dbuo2f7xysrt/LDh2kDY4b59i1B9lQwYsMCIWOmKFGyvbcQBPrkf+o2H+H6d06cwJJQj8juA7UDXGNoZhC1WawLdu89o1XL6yqofa8WOAxw+8gq9es0zRuVdEXd9ZU28VVC0CxwJYIvp+D6FISHxkUuSlApMA/4ZivoMDFqLIjvqlZlMMchyfdlcgy5A/BlgrvNW2CPH7y/f9Wnn9CkMCdVk59+BuwG9oR0kSbpRkqS1kiStrVnhZ2AQaqKi0nE4+tcqG3DGfVitXXci97QmaSBc9W9IGuz3ifcdDxmXwo734avHwdP5IbHhQJtdK5IkTQcKhBDrJEma0NB+QojFwGKAkSNHGqEEBu2C3Z5KdtZzlJevx+MtICY6h6iorM7ulkFjpI2Dc+6Ggm2QtwY+fdBfbnaAka+1WYTCRz4OmCFJ0oWADYiWJOkVIcTVIajbwKDFOBx9cDj6dHY3DFpCYn947+fgO0kz/py7wFLfVWZQnzYbciHEvcC9AMdH5HcZRtzAwKBF9MiB6/4LP34E7nIYPB1Sc5s+zgAw4sgNDAy6Cik5/o9BiwmpIRdCrARWhrJOAwMDA4PGMUbkTVDh8rIt30l+uZvUWDtDUqKJtBqXzcDAoOtgWKRGcPtUFn+5jydX7A6ULbhgMD8b1xezyZhNNzAw6BoY1qgRdhdU8dTK3bXKHvv4R/YWGaI+BgYGXQdjRN4I5S4fdcXzVF3gdDcv76NX1dhbVEVJlZeesXb6JES0Qy87Fl33IkmKoVtiYNCFMAx5I/SJdxDrMFNWfcJwd4+2kRrftNCUy6vy2vcH+b+PdqDpgiiriWd/MoKx/RPbs8vths9XTnHJl+TlvYLVmkyv1GuJiRmOZCzYMDDodIxvYSOkxjt4/tpcBnf355rMTo1h8U9G0D26aUO+81glD3+wHU33D+mdHpVfLd1IQYW7XfvcXhQUfsLWrb+kvHwtBQUfsf6Ha3A6t3Z2twwMQsahikP8b9//eHvX22wu2oyqq53dpWZjjMibYESfON64cTRl1T7iIizE2M3NOi6/vH4qtaMVboqrvCRHt0+C4/bC6yvjwIHaWXuE8FJWtpbo6Mwmj6+qqqKqqgqHw0FkZGR7ddPAoNUcqjjEzctv5qDzIACKpPCPyf9gTMqYTu5Z8zAMeTOIdViIdbRMPa9nbP1Re2qcnYTI8FPhkyQZWarf7+YoCh46dIh3332XoqIi4uLiuPjii0lLS2uHXhp0WbxVcGwrlB6A6B7QLQPssZ3dq1psKtoUMOIAmtB4fP3jZCRmEGWJ6sSeNQ/DtdJODOgWxSOXZGBW/FlO4hxm/jInm+So8BqNA5hN0fTtd0etMkWJJCZmeKPHlZeXs3TpUoqKigAoLS3ljTfeoKSkpN36atCOOI/607K1BF3zS9I+PwXevh6WTINVjzWuauhz+VO+rX0Rtr0HZYfa1u9mUO4pr1d2tOooHtXT7m2HAmNEHgRNFxwsqcKr6qTGOYhoxQIgm1nh8txenNk3npJqf9RKalz4CgAlxJ9DTvYSCgr/i8WSRFLieURFDWn0mLKyMiora39h3W43ZWVlxMfHt2d3DUJJVSFsXAqr/womK5z7AAy5CGzNyCFTvMef8edkvn4C0i+Fng0MBLa/D2/fcGI79UyYuwSiU1p9Ck0xNGEoEhKCE2FqcwfNJcHe+QnJm4NhyOtQ7vLy+neH+NvynXhUnXMHJfHgRUPpm9hy365JkRnQreu/ljUHkymChISzSUg4u9nH2O12FEVB07RAmSRJOBzh+4N2WrLz09rG+N1bISIJBp7X9LGeCgg2qnWVBt+/4gj8b0Htsrzv4OjmdjXk6QnpPH7u4/xl7V8ocZdw2aDLmHnGTKQwyRtqGPI6bDhUxh/+tyOwveLHQtISDvDA9KEocutvapHTzdYjTsqqvfRLimBwj2jMyqnt2UpISGDKlCn873//C5RNnDiRhISuPcrxulXKC1wgQUySHYvtNP6aqF5Y90L98h0fNM+Qx/SGuDQo3X+izBLpLwuGzx3cyHuczehs6zErZs7tfS7Dkofh0TwkOZKQwyi09jR+QoOz5XBFvbIPNudz27lnkBhlbVWdhU439769meXb/f5FWYJnrh7Beend29TXro6iKAwfPpzU1FTKysqIjo6mW7dumM3Ni/zpDMqLXKx+cyf7NxUDcMaIZMbOOoOo+PCb2wgJsgJxff0JH04mtpl671HJMOcl+PDXcHgtJAyAixZBQv/g+8f0hIxZtRMyK2ZIGtS6/reQWFvXmoRtLoYhr0Of+Pqv/Zk9o4lsw6hsW35FwIgD6AIeeGcLOb1iu3wootdbiq57sdm6tep4i8VCamoqqampIe5Z+7BvQ2HAiAPsXldA6uA40s8+TRM3ywqceZM/9ZrveEitIx4GTW1+HSk5cPXbfl+7PQ4iGnkjM1nh3PvAFgub3oD4/nDew/5IF4MGMQx5HYb3iWNM/wS+2eP/MkfbTdwxeSA2c+uXpJdX11/SX+D0UOXVguzdNdA0N8XFK9m950+oagW9Uq8jJWU2VmvjBt3nq8DrLcRkig67PJlCF+zdUD+f7IEtxaevIQdIHQk/+xTyN4Fi8ieBaOkI2R7j/zSH+H4w9Q9w1p1+N0zNceWHQXVDTKrf4BsEMAx5HVJi7Txx+TB+PObE5dU4IzmStMS2aaT0S4pElvwj8RomDkqiW3TXfRgrKjayecttge29+/6KLFvp0+f6Bo9xOrexfccDOJ0bsVp7MGTw/xEff1aXWsZfkl/Fwa3FlB6tpk9GAikDYrFF+F09kiyROiSe/N21Q9FSBsZ1Rle7Ft0z/Z+OQjH53SzgfxPY+g58fC+4y/wRLxMf8Bt8A8CIIw9KYpSVcWckMnlotzYbcYDB3aNYfM1IesT43SiThyRz/7ShOCxd93e0rGxNvbLDR17F6w0ebeD1lrJ1269xOjcC4PHks3HTTVRV7WnXfraE8iIXHzyxga/e2s221Uf47zOb2fFNPi6nh+LDlVQ7PQwYmUxC6ol7ntw3mr6ZXXty9pTnyAZ452b/JKgQsOXf8M3ToIXPEvr2putaklMIkyIzeWg3snvFUOXR6BZtw27p2uqBZkt942Wz9kBRgvv0PZ4jVFXtrFUmhBeX6wCRkQPapY8tpTivEmdJ7VC47z/Yh9etseaDfUQn2Zl87RBm3J5D6dFqJAliu0XgiA6/1binFAXb65dtfhPO/lW7hiSGE20ekUuS1EuSpBWSJG2TJGmrJEl3NH3U6UlSlI20xIgub8QB4mLPxGrtEdiWJBNpfW9HUYILhimmaBSlfqy92dy4W8LtPkJR0UqKilbidh9pW6ebQNf0emWaqqP5/OUVhS4+emYzmiroOTCOlAFxhhHvCkQGmWuJP8PvPzcAQjMiV4FfCyHWS5IUBayTJOlTIcS2ENRt0ElERPRj+LBXqHBuRtNcREUOISoqvd5+XrdKZakHiy2JQQN/x7btd8Hx1XGpPa8hIqLh0Xhl1W42bvwZbnceADZbL3Ky/0lExBntck4JPSOx2E14XSdeyQeN6s7+TUWBbXelD2ex+/QNN+yKpAzzr+7M+86/rVhgykPNW1l6mtBmQy6EyAfyj//bKUnSdqAnYBjyMMfhSMPhSGvw7yX5VaxaupO8HaVYHSYmXjuKkSPexuU+iNWSRGTkYMzmhr9sBcc+DBhxALf7EMcKPqJf39tDeRoB4rpHcPEvh7H5izyK8yoZOKobJUeqKMk/kfFJViRskYbHsUsRkwpzX/Kv7vQ6IXEQdKs/qDidCekTK0lSGjAM+C7I324EbgTo3bt3KJttFS6fyg8Hyvhk6zHiIsxMGtKNjJ7NDI8yQPVqfPfuHvJ2+Cc/PdUq//3HDmbdPYLu/bKaVUd5+bogZT+EtJ91Se4TxblXD0ZTdSQJNq3Iq/X3cbMHEJtsSAh0OaJ7+D8GQQmZIZckKRL4N/BLIUS95ZFCiMXAYoCRI0eKun/vaL7aXcz1L60NbC/+ci/Lbh7L0BTjda05VFd42buxqF552bFquvdr3g9icrdplJR+VausW/IFIelfY8iyhHx8niJzfE9SBsRSVeohMs5KQs9I5FNcOqFLo6ngPAKy2TDcLSAkhlySJDN+I/6qEOLtUNTZnlR5VBZ9tqt2mVfj233FhiFvJmabQmyynbJjtRNo2KOav/w+IX48qT2v4fCR1wDomXIl8QnjQ9rPpjBbTXTvGwN9O7TZUwddhyM/wO5P/ZK1A8+DlOH+FaEtpeyQXxlx3QtgjYbzHoEhF4M1/HPdtjdtNuSSXx7seWC7EOKvbe9S+6MJQZWn/qpKj69+VINBcOyRFs65fBAfPLkRXfO/YPXNTiSxV/PVHm227gwYcB+pqdf467T3alayCoMuxOF1sOQC0I6vXl79V5j3IfQe3bJ6hIAfXoHvn/VvVxfDO7f4/eN9zwltn09BQjEiHwdcA2yWJGnD8bL7hBAfhaDudiHaZuaWCf24a9mmQJkiS4zuZ2hkt4TUQXHMvS+X0mPVWB0mElIiWxyuJ8sWIiIaEFAy6Fx8Ln8iCUtkw/ooG18/YcQBdBXWvtByQ15dBBteqV9+aI1hyJtBKKJWVgPhIdp7EpOHdGPR5Tm8+PV+EiIs3HB2P7JSw1P5rLOQZImEnpEk9DTieU85CnfC5w/7xbLi+8OFj0Hf8SDXmT9w11cLxV0/206TmB3+JffltSefiTEW/DSH0zbOKtZhYUZOT85P744iS5iMCS4DAz+eSn9yhz2f+beLd8Nrc+DGL+qH/eVcCVuW1S4b+dOWt2mJgAn3waHvTiSiSBwEvVo4sj9NkYTo+ACSkSNHirVr19Yq8/l85OXl4Xa7O7w/BgYGJ6H5wJlfvzwi0T9yPhmh+w2vp8K/DswW7VcmbK1Qmub1ty/Jfh1yuf3GmjabjdTU1Bbr4+s+DUmRkdqQaKa1SJK0Tggxsm55lxmR5+XlERUVRVpaWtikVzIwOCVRvVAIiDoBAfH9G15NqR8PFKjrejkZTfUbalkGxQqd+D0XQlBcXExeXh59+zYvZEktcVG9sRDXpiIsadFEnNkDS/euEVHTZQy52+02jLiBQVfAZPFHi5QdOFFmjQFzcJ0doHEDDv6J09IDoLr8o+3oFLDHty5MMQRIkkRCQgKFhfX154OhezXKPtqPe4t/7YQvvwr3tmKSbs7GFNf5cg5dxpADhhE3MOgq2GIh0epP5CCb/C4VpZUp+nTNn1RZPb7mQOj+SU2THaydN1HeEnujlrgCRrwGrdyLr6DaMOQGBgZdFFn2T0BaQuA60FW/D70umgcIj4gnSZL8WrF1lppIXSRIomv04hRm5cqVTJ8+HYD33nuPP/zhDy06/sILL6SsrIyysjKefvrp9uiigUFwhABftT+hg7uidrx4S5AV/+i7XnnXTcJdF1OCncgxtUMhzamRmLo14m7qQMJ2RP7OD4f588c/cqTMRUqsnfnnD+KSYe2fV1EIgUfV0YXAosgtClucMWMGM2bMaFF7H33kX1e1f/9+nn76aW699dYWHW9g0Go8TijZS40sMdYYiO3VcheLbPL73Ev2+N0q4PePN+ZzDxG6qoOqgywhmVofaSKZZKIm9MLSOwr37jIsPSOxDYjDFNU10jWG5Yj8nR8Oc+/bmzlc5kIAh8tc3Pv2Zt754XCb6r3kkksYMWIE6enpLF68OFD+/PPPM3DgQHJzR/GT637GdTfcwu6CStZsP8AlMy8lNzeX3Nxcvvrqq0ZqhyVLlvDzn/8cgHnz5nHLLbcwevRo+vXrx8qVK/npT3/KkCFDmDdvXuCYtLQ0ioqKWLBgAXv27CEnJ4f58+e36TwNDJpE80H5IQJGHMBT7p+0bA3WSH9ceHw/SBjgz8fZWp97M9E9KuqxatQiF2pBNZrTi9BbH26tRFlwZCcTP2sgkaNTMCV0jdE4hOmI/M8f/4jLVzs0yuXT+PPHP7ZpVP7CCy8QHx+Py+UiNzeXWbNm4fF4ePjhh/nq2zXIVjvTzp/CwKEZADz8wHzm/exmZk2bwuG8Q5x//vls3x4kLVUDlJaW8s033/Dee+8xY8YMvvrqK/75z3+Sm5vLhg0byMnJCez7hz/8gS1btrBhw4ZGajQwCBFC94cK1kVvQ55Ms83/6QCEpqOVevzuoePoTi+yTUGyhqXZa5SwPKMjZcFHBQ2VN5dFixbxn//8B4BDhw6xa9cujh49ytnnnINLthEpm5gy/RIO7N0NwLerv2Dvrh959AEFSYKKigoqKyuJjGzeBM5FF12EJElkZmbSrVs3MjP9WcrT09PZv39/LUNuYNChyCa/K8VTZ7m9qWu4EppC6AKh1hfBE1qnK2i3C2FpyFNi7RwOYrRTYlv/qrNy5UqWL1/ON998g8PhYMKECYFVpkJAtVcjylb7VVDoOm999DmDUxNatcTfavV/KWRZDvy7ZltVjQzhBp2IrPhjvct1f1aeGj93B/i1Q4GkyEhmBVHnzb0mykToAnTRJldLVyIsfeTzzx+E3Vx7IYHdrDD//EGtrrO8vJy4uDgcDgc7duzg22+/BSA3N5fVq76kqqIcZ7WHL/73fuCYsedM5N3XXggY8fZ0e0RFReF0OtutfgODephtEN8Xkob4/dv2uNYvve9gJFlCibNCzQBLAiXWimSW0X0aaokb39Eq9Eov7t2ldIRUiVrqxnOwArWkbZ6DYITHXanDJcN68vtLM+kZa0cCesba+f2lmW3yj0+dOhVVVRkyZAgLFixg9Gi/WE/Pnj257777uHrGJGZeMImUXr3pnhhPSqydZ//xJJs2rCcrK4uhQ4fyzDPPhOgM65OQkMC4cePIyMgwJjsNOg5Z8Rt0U/jpxMsWBXOyHVOSA1OyAznC/0atlXoQbv8br9AERS9uRT1W3a59ce8qpeDJDRQ+vZFjT2zAta04pG8DXUY0a/v27QwZMqTD+9IcKisrcUREUOXyMGf2LH4y7zrmzrrUUEw0MAgzdJ9Wy2j/eHA3ce9VEn/1EBwZie3Splri4tgTGxCuE+5SySyTfPswzEktyw/bkGiWYYmawcKFCxk+bBi5w3MYeEZ/rpgzyzDirUTTNbyaF10Y2ZgMOh7/Cs36seSyvf2mC7UKby0jDiB8OlqZJ2RthOVkZ0fz2GOPdXYXTgmqfdUcrTqKW3MTZYkiyZ6EzdT5OhUtoeYN1tAFCi+EEKAJv688xopWekIu256ZiLkdVQzlCDOSWUacnEpSllCiQueuMoaVBh2CR/VwoOIALtWFEIIKTwVHKo+g6fVzp3ZFdF3gcfkoL3BRXuDC41JPmYiHUx2h6n6Bq2PVqIUuJEXClGRHibOhRFqIndEfJaL9FieZEuzEzhpw4k1AgtiL+2NKCl0EkDEiN+gQvHp9d4pLdeHVvdjlrh/S5vNolBeciDbwulVikx1Y2vGV3KDtCCHQKn3olf7FTUIVqEUuTEkOlAgTklkO6cg4GJIs4chMwtI9ArXcgxJlwZzsCKngVkhqkiRpqiRJP0qStFuSpAWhqNPg1EIOErYmSRJymLwUup31Vzm6q1opImXQcWgCPch9EmrHvglKioS5ewT2QfFYUiKRTKF97ttcmyRJCvAUcAEwFLhCkqShba3X4NTCqliJscbUKuvm6IZFCZOwtmA+ccNN3vWR/Ea0fnnLb55a4sK1rZjqrUWoxaGPBW8LoXgvHAXsFkLsBZAk6Q3gYmBbCOoOO9LS0li7di2Jie0TytRWOqt/JtlEN0c3YqwxqLqKRbFgU2xhM2lojzLjqa49srO1o1/VIDRIiowSa0UtOmF4JbOMbGlZZiLf0SoKX9yCXu5/M5OjLST9NKNdJ0lbQigMeU/g0EnbecCZdXeSJOlG4EaA3r17t73VTW/CZw/5M43EpMKkByFrbtvrNWgQVVUxmVr/yJgVM+Z2VrxrL8xWhdhuDjzV/jAyq8OE2do5acpOR4QuQIhW+ZUlq4Ip2eGPGpH8C4Va6tqo3lQYMOIAeoWX6o2FxHQRQ95hDkohxGIhxEghxMikpKS2VbbpTXj/9hMym+WH/Nub3mxTta+88gqjRo0iJyeHm266CU3TWLNmDVlZWbjdbqqqqkhPT2fLli1omsZdd91FRkYGWVlZPPHEE4F6nnjiCYYPH05mZiY7duwA4Pvvv2fMmDEMGzaMsWPH8uOPPwJ+adtLL72UqVOnMmDAAO6+++5APTXyuaNGjeKGG24ISOAWFhYya9asRuVzQ9m/GTNmMHHiRCZNmkR1dTVz585l6NChzJw5kzPPPJOaxV2ffPIJY8aMYfjw4cyZM4fKyso23Y+uhCRJWGwmouJtRMXbsNhMYfM2Ec4IXaBV+1AL/REnWpUPobVsDYIkScgWBSXCjOIwt8o/7c2r/yx7DwXJetRJhGJEfhjoddJ26vGy9uOzh+rrIvtc/vJWjsq3b9/O0qVL+eqrrzCbzdx66628+uqr/OQnP2HGjBk88MADuFwurr76ajIyMvjHP/7B/v372bBhAyaTiZKSkkBdiYmJrF+/nqeffprHHnuMf/7znwwePJhVq1ZhMplYvnw59913H//+978Bv0bLDz/8gNVqZdCgQfziF79AURQefvhh1q9fT1RUFBMnTiQ7OxuAO+64gzvvvJOzzjqLgwcPBpXPXbx4ccj6t379ejZt2kR8fDyPPfYYcXFxbNu2jS1btgQUGouKinjkkUdYvnw5ERER/PGPf+Svf/0rDz74YKvuh4EBgPBqaCUnYr61UjfE21AcHTtJ7shOwrOztHZZTnKH9qExQmHI1wADJEnqi9+AXw5cGYJ6G6Y8r2XlzeCzzz5j3bp15ObmAuByuUhO9t+oBx98kNzcXGw2G4sWLQJg+fLl3HzzzQFXQ3x8fKCuSy+9FIARI0bw9ttv+7tWXs61117Lrl27kCQJn++Ev3XSpEnExPgnAocOHcqBAwcoKipi/PjxgXrnzJnDzp07A21v23ZiCiKYfG4o+zdlypTA8atXr+aOO+4ACIz2Ab799lu2bdvGuHHjAPB6vYwZM6a5l9/AICh6dX0VUL3Kh2zv2Dci68A4IiekUrnKP0aNPCsF68C4Dmu/KdpsyIUQqiRJPwc+BhTgBSHE1jb3rDFiUo+7VYKUA15Vw+XTEUJgNSnYmzGxIYTg2muv5fe//329vxUXF1NZWYnP58PtdhMR0bhfrEaSVlGUgBztb37zG84991z+85//sH//fiZMmFBv/8VLIpoAACAASURBVLrHNISu63z77bfYbK1bFdnS/jV1vuC/flOmTOH1119vVZ8MDIISJOIkaBRKO2OKshAzJY2I3O7+7Vhbp/SjIULyfiKE+EgIMVAI0V8I8Wgo6myUSQ/W10U222HSg3h8GvuKqjlQXMXBkmr2FFZS5Wla23vSpEm89dZbFBQUAFBSUsKBAwcAuOmmm3j44Ye56qqruOeeewD/KPXZZ58NGMKTXRfBKC8vp2dPvzrjkiVLmuxPbm4uX3zxBaWlpaiqGnBzAJx33nm1fN7B5HPbq3/jxo3jzTf9cxHbtm1j8+bNAIwePZqvvvqK3bv9STeqqqoCbxAGBq1FtptqhwpKIEdYOmV+QlIkzAl2zAn2LmXEIVyX6GfNhYsWQUwvQPL//6JFkDWXKq+G56Rgf10IjlW40ZtYTj106FAeeeQRzjvvPLKyspgyZQr5+fm8/PLLmM1mrrzyShYsWMCaNWv4/PPPuf766+nduzdZWVlkZ2fz2muvNVr/3Xffzb333suwYcOalTSiRj531KhRjBs3jrS0tID7ZdGiRaxdu7ZR+dz26t+tt95KYWEhQ4cO5YEHHiA9PZ2YmBiSkpJYsmQJV1xxBVlZWYwZMyYwkWpg0Fpki+JfTh9rRYm1YkpyIFnC02y1J6ecjO2xCjfHKty1yiyKzBnJkWGnWFjj91ZVlZkzZ/LTn/6UmTNndmqfNE3D5/Nhs9nYs2cPkydP5scff8Riaf7CHiEEXs2LV/eiSApWxYoiG6F8Bh1PqOWzfYX+ZM+y3YQp2YHiCG24bUMytqecUEREEH94tN2MR9WRZQk5jELGFi5cyPLly3G73Zx33nlccsklnd0lqqurOffcc/H5fAghePrpp1tkxAGqfFUcdB4MKAkm2BNIsicZxtwgrPHsK6foxS0Irz880jE8mZgL+6JEtv/q5VPOkNstJlLjHBwtd6EJiLWbEcCewkr6JUYQaQufBSldUT43KiqKum9TLcGn+ThSeaRWaq1iVzFRligi5K6xuMLAoKXo1Spl7+8JGHGA6vUFOHKSUQYahrzFKLJEfIQFEHhVnQq3ivt4AtbiKi8RVmMhR2eiCx2fXl/ESNWNZNMGzUPoAqEJJImQi0+1Ft2j4suvqleuVYQueURjnHKGvIZqr0ZJVW3Fuk6YDuh0dKHj0TxouoZFsXS6SJUiK9hMNtxqnXkMOUzEsww6Fd2no1d40F2qPzlDrBXZZkIKkvUnGEIIhCpA0/364CEyCnKEGevAODw/1l40ZEroGInmsDHkmq7jPh4bbjHJWEyN+1NjHZZ6hjwhsnPCljoLTdcocZdQUO0PqVQkhV7RvYgwd54LwySbSIlMIc+Zh1fzIksy3SO6YzVZmz7Y4LRGCIFe6fUbcQBdoJW4kZLsSNbmmTLh0VCL3QEDrns0dK+KbGmbKZQtCjEX9KXU6cN3pBLJLBN9QRrmlI75roWFIfeqGsVVXoorvehCEGE10SPahqORm+ewKPRLiqSk0oMA4iMsRLTxZoUbHs0TMOIAmtA4UnmEvjF9Mcmddy3sJjt9Y/ri03zIsoxFPr1+YA1aiSaCrvQUPh2aMQ4Qqo5a6q41CtddKr6j1Vh7R7epa2qJC+FSiZs9AAHIFhlTvL3ZbwptpWs4mJqg2qtR6PSgH78BVR6V4iovmt6weI4sSURaTfROiKBPQgRRNjNyIxd1//79ZGRktKhf8+bN46233mrRMR1JjS/68MHDfPjvDwHwat6Qp1c7WRogGGVlZTz99NO1ykyyCbvZjlWxNmjEFy5c2KIJX4/Hw+TJk8nJyWHp0qX83//9X7OPbYgJEya0aXL3ZFpzndqLmnj/v/3tbx3SXkiQQTIFeVaauThH6MfzdtZBq6ifNKQluHeXceyJDRQ+u4mCpzegHqn0r/zsICMOYWLI3b76BvujfR8x9d9TyXopi/PeOo8P937YCT3r2phlf4TO4UMnDLnV1PEx2x1loH744QfAv9L1sssua5Uh17TOyyHa2HVqziKy5nL06FHWrFnDpk2buPPOO5t1TCjbby2SLKPEWGsl9JAsCrK5ec+zpEgQZHLUFNt6t55a7qHkjR2IGnePKij99y58BdWtrrM1hIUht9S5+F/lf8Jz2/7I0ep8BIL8qnwWfr2wzcZcVVWuuuoqhgwZwuzZs6mu9t+Mhx56iNzcXDIyMrjxxhsJtoiqoX0mTJjAPffcw6hRoxg4cCCrVq0CGpaZXbduHePHj2fEiBGcf/755Ofn12tr3rx53H777YwdO5Z+/foF3gqEEMyfP5+MjAwyMzN596136RbRjb8//HfWf7ue2efO5t///Hctt8rKlSuZPn16YPvnP/95YIl+Wload999N5mZmYwaNSqw/H7fvn2MGTOGzMxMHnjggcCxlZWVTJo0KSCR++677wKwYMEC9uzZQ05ODvPnzwfgz3/+M7m5uWRlZfHb3/42UMejjz7KwIEDOeusswJSunV5//33OfPMMxk2bBiTJ0/m2LFjFBQUcPXVV7NmzRpycnKYM2cOLpeLnJwcrrrqKiC4TDH4R8q//vWvyc7O5ptvvqnX3r/+9S9ycnLIyMjg+++/B1onS1xDUVERY8aM4cMPaz+vda/TypUrOfvss5kxYwZDh/qTbl1yySWMGDGC9PR0Fi9eHDg2MjKS+++/n+zsbEaPHs2xY8cAWLZsGRkZGWRnZ3POOecAfomHw4cPk5OTw6pVq9izZw9Tp05lxIgRnH322YEVufPmzePmm2/mzDPPDHoerUXoAt2lopa4UMs86N7m/3hKVsWfbzPehinBjinB1uzIFUmRMcVZayVBlh1mzN0crTkNAHSnF72yThSWAK28Y6JVTrQpRId/RowYIeqybdu2emU1uL2q2F3gFBsPlYqNh0rFhDcmiYwlGfU+U5ZNabCOpti3b58AxOrVq4UQQlx33XXiz3/+sxBCiOLi4sB+V199tXjvvfeEEEJce+21YtmyZY3uM378ePGrX/1KCCHEhx9+KCZNmiSEEOLpp58Ws2bNEj6fL3C81+sVY8aMEQUFBUIIId544w1x3XXX1evrtddeK2bPni00TRNbt24V/fv3F0II8dZbb4nJkycLVVXF0aNHRa9evUTe4Tzx8fKPxdQLpwqv6q1X14oVK8S0adMC27fddpt48cUXhRBC9OnTRzzyyCNCCCFeeumlwH4XXXSReOmll4QQQjz55JMiIiJCCCGEz+cT5eXlQgghCgsLRf/+/YWu62Lfvn0iPT090MbHH38sbrjhBqHrutA0TUybNk188cUXYu3atSIjI0NUVVWJ8vJy0b9//8A9OJmSkhKh67oQQojnnnsucH3rnktNv4TwP1/Tp08XXq//Gtxyyy2BcwDE0qVL67UjhP/+XX/99UIIIb744ovAeZSXlwfu3aeffiouvfRSIYQQL774oujbt68oKysTLpdL9O7dWxw8eDDQn6NHj4pRo0aJTz75pF5bda/TihUrhMPhEHv37g2U1Txn1dXVIj09XRQVFQXOoeaZmz9/vnj44YeFEEJkZGSIvLw8IYQQpaWlQduZOHGi2LlzpxBCiG+//Vace+65Qgj/czZt2jShqmrQa9Na1Cqv8ByqOPHJcwrNE9o2GkP3aUJzq0LzqmLb1obtTnPwlbrE4Ye+EYfu+fLEZ8GXwpPnDFFvawOsFUFsaljM/lnNCr3jHLh8GroQFLsLgu53tOpom9rp1atXQIb16quvZtGiRdx1112sWLGCP/3pT1RXV1NSUkJ6ejoXXXRRrWMb2+dk2dj9+/cDwWVmt2zZwpYtW5gyZQrgH7X36NEjaF8vueQSZFlm6NChgdHX6tWrueKKK1AUhW7dujF+/HjWrV1HdHQ0iqS0KjvPFVdcEfh/zWv4V199FRDxuuaaawJCYkII7rvvPr788ktkWebw4cOBvp3MJ598wieffMKwYcMA/0h+165dOJ1OZs6cicPhHyHNmDEjaJ/y8vK47LLLyM/Px+v10rdv3ybPozGZYkVRmDVrVpPX4JxzzqGiooKysjKcTmeLZIl79eqFz+dj0qRJPPXUU4wfP77JPgOMGjWq1vktWrSI//znPwAcOnSIXbt2kZCQgMViCbxZjRgxgk8//RTwi5zNmzePuXPnBp7Dk6msrOTrr79mzpw5gTKP58Rocs6cOShK6FxxQhfodRNZC4HwatDC9GutRTLJSDWWr41ubFOsjfi5Ayl+dbt/MZAsETujH+bkjgk7DPSjQ1trA2aTjPn4K1T3iO7kV9V3OXSP6N6mNupOukmShNvt5tZbb2Xt2rX06tWLhQsX4nbXjoFuap9gsrHBEEKQnp4e9PW+LidL34o6rp6WTGaaTCb0kyaN657bydekoX/X8Oqrr1JYWMi6deswm82kpaXVq6+mv/feey833XRTrfK///3vzerzL37xC371q18xY8YMVq5cycKFC5s8RjQiU2yz2Ro1VsGei9bIEptMJkaMGMHHH3/cbEN+soTwypUrWb58Od988w0Oh4MJEyYErq/ZbA708+Q2n3nmGb777js+/PBDRowYwbp162rVr+s6sbGxQRU067YfEsTxT7DyDkAIgVD9z3uoFhNZB8aRfPtwtDIPSqQZU6K9wxcqhYWPvC53DL8Dm1Jbi9um2Lhj+B1tqvfgwYMBI/raa69x1llnBb4oiYmJVFZWBo1Sac4+dQkmMzto0CAKCwsDffD5fGzd2nxp97HjxvLK66+wq2QX6/eu54svv2Bk7kiioqJwOp1Bj+nTpw/btm3D4/FQVlbGZ599VuvvS5cuDfy/JlHEuHHjeOONNwC/8a6hvLyc5ORkzGYzK1asCMgA123//PPP54UXXgikgjt8+DAFBQWcc845vPPOO7hcLpxOJ++//37QPp8sufvSSy81eD3MZnNgpNyYTHFT1FyD1atXExMTQ0xMTItlicH/A/DCCy+wY8cO/vjHP9b7e2P3CfznHRcXh8PhYMeOHXz77bdNtrlnzx7OPPNMHnroIZKSkjh0qLaOf3R0NH379mXZsmWA39Bt3LixWefTGiRFQo6qs/hL8vu+2xuh6mhlHtRj1ajHqtHKPf5IljYiSRLmRDu2M2Ixd4/olNWmYWnIp/WbxsKxC+kR0QMJiR4RPVg4diHT+k1rU72DBg3iqaeeYsiQIZSWlnLLLbcQGxvLDTfcQEZGBueff37g1fxkmrNPXYLJzFosFt566y3uuecesrOzycnJ4euvv252/ydNm0SfQX246OyLuGrGVdz+wO3EJMaQlZWFoihkZ2fXCzfr1asXc+fOJSMjg7lz5wbcHTWUlpaSlZXF448/Hjj28ccf56mnniIzM5PDh09k9bvqqqtYu3YtmZmZvPzyywwePBiAhIQExo0bR0ZGBvPnz+e8887jyiuvDEyYzp49G6fTyfDhw7nsssvIzs7mggsuaPA6Lly4kDlz5jBixAgSExMbvB433ngjWVlZXHXVVQ3KFDcHm83GsGHDuPnmm3n++eeBlssS16AoCq+//jqff/55vQiVutepLlOnTkVVVYYMGcKCBQsYPXp0k+3Nnz+fzMxMMjIyGDt2bCBd4Mm8+uqrPP/882RnZ5Oenh6YpG4vZLuCkmBDsirIDjOmRAeSuf1Nke5W0atOuMD0Sl9gdB7unHIytqcrmq6xr3wfHq32bHmSI4lkR+tyC6alpbF27dpGjaWBQWsRQnTYQjAhBGqhy++LP4md+fvIyM3qkD6EgoZkbMNyRG5QHwkpaHy4IhnSsAZdk45czStJUlD3TdAFRmFImwy5JEl/liRphyRJmyRJ+o8kSbGh6phBy5BlmSR7Uq0yRVLapKuyf/9+YzRucMogO0xwcnIZk9whLp2OoK1n8SmQIYTIAnYC97a9SwatxWF20DemL8mOZLpHdCctJg2bqXUJmg0MTjVks4I5ye5fSJRox5xoRwqzrGEN0abwQyHEJydtfgvMblt3DNqCLMk4zA4c5tavVKvBq3lxep1UeiuJsEQQbYnudAlcA4O24o8hPzWM98mEMo78p8DSENZn0Eloul8lscrnF8qv9FVS6a0kNSq1U1UTT2Vcmk6lpqHqgiiTgkORwyotoUHn0uS3UpKk5UCwlTb3CyHePb7P/YAKvBpkv5p6bgRuBOjdu3erOmvQMXg0T8CI11Dlq8KreQ1D3g64NZ091e6AMF+BVyXNbiHGbFxrg+bR5DuGEGKyECIjyKfGiM8DpgNXiUZiGYUQi4UQI4UQI5OSkhrardM4FWVsa9i/fz+vvfZau9XfXvKsXUHGNhh1hcbaSpWm11NXPerxoXXhlFatefZbej/bwtixY4H2f/a7Cm2NWpkK3A3MEEJ0qG5j+fvvs2viJLYPGcquiZMob2AVoEHLH2aLYqkX7eIwO1rtIzdkbBtHD7I+XaO+9EJr6QoStB1NzUI6w5A3jyeBKOBTSZI2SJL0TAj61CTl779P/m8eRD1yBIRAPXKE/N882GZjfqrJ2NYsLV+wYAGrVq0iJyen3srOYDK2r7z8CimRKVww4gIWPbyIORPmMHfyXPbv3Q+cXjK2u3fvZvLkyWRnZzN8+HD27NkTONfZs2czePBgrrrqqsD9buj+rVu3juzsbLKzs/nlr3/N4PR08j1enn3+BR745S8D4k2/mDuLNau+JMli4vPlyxkzZgzDhw9nzpw5AUmDk9mwYQOjR48mKyuLmTNnUlrqzxk5YcIEfvnLXzJy5Egef/zxWsdUVlZy3XXXkZmZSVZWVkAA7ZZbbmHkyJGkp6fXuicLFixg6NChZGVlcddddwXKv/zyy3rPYF0aup9NSeeOHDmSgQMH8sEHHwB+GYyaPg8bNowVK1YAsHXr1sA9zcrKYteuXYF7WtP3hp79U4pgkojt/WmpjG1ddp47UWwbNLjeZ+e5E5tdR11OVRnbI0eO1JN3PRlDxrZxGdtRo0aJt99+WwghhMvlElVVVWLFihUiOjpaHDp0SGiaJkaPHi1WrVrV6P3LzMwUX3zxhahSVXHt7XeI/kOGiA3lVeJ3/3hG3HjLrcLpU8XuKpcYP3WqeOeTT8WRY8fE2WefLSorK4UQQvzhD38Qv/vd7+r1LzMzU6xcuVIIIcRvfvMbcccddwgh/M/dLbfcEvSc7r777sB+NddTiBPPsKqqYvz48WLjxo2iqKhIDBw4MHC9a6RwG3oGT6ax+9mYdO75558vNE0TO3fuFD179hQul0s89thjgWu5fft20atXL+FyucTPf/5z8corrwghhPB4PKK6uloIceLeN/bsC9Eyu9MVIJxlbOuiNqCR0VB5czkVZWzXrFlDdHTr8xGezjK2TqeTw4cPM3PmTMCvuVLDqFGjSE1NBSAnJ4f9+/cTGxsb9P6VlZVRVlbGOeecwxG3l2mXXcHqT49H7gpw6ToRikxfu5UIRSHGbGLd99+zbdu2wPPo9XoDomU1lJeXU1ZWFlBSvPbaa2vJ0V522WVBr8Xy5csDomcAcXFxALz55pssXrwYVVXJz89n27ZtDB06FJvNxs9+9jOmT59e6+0t2DN4MqtWrQp6P5uSzp07dy6yLDNgwAD69evHjh07WL16Nb/4xS8AGDx4MH369GHnzp2MGTOGRx99lLy8PC699FIGDBgQ9JxPdcLSkJt69PC7VYKUt4VTRca2Lpquoeoq+ZX5WBQLkebIQNZ6Q8a2aRnbYASTqm3o/pWVlQX+XVeiyWQyBXLPypKE5/j1EkIwZcoUXn/99Rb162RaIkG7b98+HnvsMdasWUNcXBzz5s3D7XZjMpn4/vvv+eyzz3jrrbd48skn+fzzz4ET10DXtBb585uSzg32PWyIK6+8kjPPPJMPP/yQCy+8kGeffZaJEyc2uy+0oN9dmbCMjE++85dIttorFiWbjeQ7f9mmesNdxvbss89m6dKlaJpGYWEhX375JaNGjQIrFJcVU+Iu4WjVUQ44D+DV/OL+hoxtw0RFRZGamso777wD+EeNNfMmwWjo/sXGxhIbG+uXwTUpfPTmieUWKb37sHvzJoQQHDp0KJBKbvTo0Xz11VeB9HpVVVXs3LmzVnsxMTHExcUF5l3+9a9/NUvnfMqUKTz11FOB7dLSUioqKoiIiCAmJoZjx47x3//+F/CPnsvLy7nwwgv529/+VkviVtc0qspKKT58CITAU11dy6A3dD+bks5dtmwZuq6zZ88e9u7dy6BBgzj77LMDz9rOnTs5ePAggwYNYu/evfTr14/bb7+diy++mE2bNtU614akgTVVxeWsoKq8jM9feIZj+/Y0ed26MmFpyGMuuogeDz+EKSUFJAlTSgo9Hn6ImDrujpYS7jK2M2fODNQ3ceJE/vSnPxGfFE9S/yRkRebSCZfy8jMv49N8uFX/j48hY9s4//rXv1i0aBFZWVmMHTuWo0cbzkLV2P178cUXue222zh75AiiTTIyEnZF5uJzx9O/Xz+GDh3K7bffzvDhwwFISkpiyZIlgWz3Y8aMCUwInsxLL73E/PnzycrKYsOGDTz44INNntMDDzxAaWlpIJfnihUryM7OZtiwYQwePJgrr7wy4NJxOp1Mnz6drKwszjrrLP76178G6vG6XTiLi9B8PgRQmn8Yn+fEG1hj97Mx6dzevXszatQoLrjgAp555hlsNhu33noruq6TmZnJZZddxpIlS7Barbz55ptkZGSQk5PDli1b+MlPflLrXINJOAshcDkrKC84hubz8cPHH7Ds4fsoPpzX5LXrqhgytqc4Xs3L7rLd9V59U6NSibHGNHqsIWPbPuzfv5/p06ezcfNmlDBdvampKiWHD6HVcRVGJybhiGm9dt68efOYPn06s2e3n9qH5vNRlHcAoQsOHD7C6qf+DMC0O+5m8Nhz2q3dUGDI2J6mmGUz8bb4WmWyJNfLsNQRCCFwazrlPpVK1b8c/XQmXI04HJeFDSKbLMlhYFKkwH9qF4dD3xsgLCc7DZqPJEkk2BIwy2ZKPaXYFBsJtoTAZGdj1ETYhIpKTWefyxOYX4o3m+hhNWOSw9egtYa0tDS2bNnS2d1oE7KiEBWfQOnRE0EHssmE2dq2AUJz0+a1BcVkJjIuHmdxUaDMHh1Dcp9+7d52e2EY8tMAs2ImwZ5ArDUWWZI7VNC/Bp+uk+f21goSKPGpxJoVooKM7Ay6Pha7nfieqfjcbiRZwWKzYbKEh0KmPSoaxWTmcFExY2ZfwYAzxxHXI6Wzu9VqDEN+GhEsg1BHoQvwBnGlqKdI+NfpiCTLWGx2LDZ7Z3elxciKgi0yEkd0DCPmXNXZ3Wkz4esUMggrTLJERBARf+tp5lYJJ3RNw+f11JvQNOh6GCPyUwxd6HhUD17dLzlrU2ydOhKvQZEketosHHR7cGsCWYKeVgu2MJ5gOpXxud2UFx5D9XpRTCaik7phsds7xS1n0DTGt6idSEtLo6ioqOkdm8mDDz7I8uXLm9zP6XWyt3wvec489pfvp9BVyPgJ46kb7tkZ2BWZ/nYbAyOsDIywEW8xGckTuiCaqlJWcBTV6z2xffQI2vHFVQZdj7Adke/87ijfvLuHyhIPkfFWxlzcn4FnBst/0f6oqhrQTAkFmqbVWjKuaRoPPfRQk8d5NS9HKmtLFxS7ikMmhxoKTLKEic5/QzBoGE1V6xltIQSa6gubyczTjbAcke/87igrXt1BZYlfaKeyxMOKV3ew87uGV901h5dffjmwMvKaa64Bgkumgn914TXXXMO4ceO45pprKC4u5rzzziM9PZ3rr7++QePZkFRoWloa99xzD8OHD2fZsmX1tmuE/P/3v//VEhs6WYb2tltvY/ak2Vx81sU8+ccnA/t0JUPeFdCEwKfr6MZ1CYosy0hB5i7kLuCiMwhOWBryb97dg+qtLT+kenW+ebf1eglbt27lkUce4fPPP2fjxo0BDeezzjqLb7/9lh9++IHLL7+cP/3pT4Fjtm3bxvLly3n99df53e9+x1lnncXWrVuZOXMmBw8eDNrOo48+ytq1a9m0aRNffPFFLW2IhIQE1q9fz+WXXx50G2Dy5Ml89913VFX5U7EtXbo08PdHH32Ud1a8w9tfvM3ar9fy49Yf/Qs3DPdFgGpNY7/Lw49Vbg67vbi1ujJWBorZTHRicq2yiLg4FGM03mUJS9dKzUi8ueXN4fPPP2fOnDmB5ejx8f7VkI1Jps6YMQO73R969eWXX/L2228DMG3atIA0aF2CSYVmZWUB9WVHg8mQmkwmpk6dyvvvv8/s2bP58MMPAz8ub7/1Ns88+wxur5uCYwXs37WfKWOmIEth+Xsdcjyazp5qDzVRkCU+DY8Q9LVZ/Qv9BChGFA2SJGGNiCShpwVN9SErJkxWC3IHTkxrqorX7cLndmO2WrHY7Chmc4e1H26EpSGPjLcGNdqR8U2vVmwpjUmmtkQmFBqWCm2ovobqv/zyy3nyySeJj49n5MiRREVF1ao7KiaK6+ZdR4wcQ5QlqkV9PJXx6Dp1Q9mrVJ0qTSPf6/cJJ1vMRJuUsF4+HwpkWUa22TDTCVIOuk5VaQnVFeWBMovdQWy37sgtlBs+XQjLodqYi/tjstTuuskiM+bi/q2uc+LEiSxbtozi4mLAL3MKzZdMPeeccwK5Af/73/8GUm6dTENSoS1l/PjxrF+/nueeey7gVjm57uLCYj75+JMuEXYYajRNw+v14vP5aumoN4dgETKSBFW6jlsTuDXBQZeXSrXj83a2B7qm4XO78bpcYRULrvp8tYw4gNdVHYiiMahPWI7Ia6JTQhm1kp6ezv3338/48eNRFIVhw4axZMmSgGRqXFwcEydOZN++fUGP/+1vf8sVV1xBeno6Y8eOpXfv3vX2OVkq9ORsRC1FURSmT5/OkiVLAj8uba1bFzoezYOqq5hlMxbF0uVcMj6fj9LS0oCGe0REBJGRkc1OCmGTZaJMMk71xA9AktlEua+24S7yqUSblLCeDYJiPAAAIABJREFUW9BUH87iYtyVfi1uk9VKbHL3MIk6CT4JLRooNwiRjK0kSb8GHgOShBBNBk8bMrZdC13olHnKyK88oc+dEplCrDW2yxgzIQRlZWW4XK5a5fHx8bVSsDWFV9dxaTpeIbDJMm5N54indqhdnFmhtz30brqOxOV0Ul5QO4rLERNLVEJil7mnDaFrGmXH8vGedK8Vs5n4lFSUEIb5QvjZnYZkbNt8VSRJ6gWcBwQP0zDo8ng1L0cra3/p86vysZvs2Ewd7yMNhq7rtfI61uDz+VpkyC2yjOWkSTtFAsl7IuOXJEGCOSxfVGtxcoKHGryuaoSuI3WAn1lTfXiqq/FUVWGx27A6Ipv9NiArCtGJybgqK44fb8ceFRNyI34qEYor8zfgbuDdpnY06JqoulrvtVUIgSa6jq9YlmUsFku9HKBtXYjlUBTOcFip1HQQEGmSsZ8CsgHB5GQtdkeHaG4LXaeytARXRQUAnuoqXE4ncT16NtsYmywWIuMSiIiNQ+okxc5wok13VZKki4HDQoiNzdj3RkmS1kqStLawsLAtzRqEGLNirucPlyUZs9x1wr0kSSIqKqpWCJzdbscSAp+vQ1FItphJtppxKOHtG6/BYrdhizwRsWSyWnFEx3TIuamqL2DEA2Veb4snKyVJQpZPjfvR3jT58yhJ0nIg2Czi/cB9+N0qTSKEWAwsBr+PvAV9NGhnrIqVXlG9yKvMQ9M1TLKJnpE9sSgtN5JC19HdboTHg6QoSHY7cojif81mM4mJiWiahiRJmEymDo1tDicUk5nopCQiYmIRCBSTueNcEw1+u42vfXvR5J0VQkwOVi5JUibQF9h4/BczFVgvSdIoIUTb1sobdDiRlkj6xfQLGHKz0jrjqzmd+A4dCmzLERGYU1NDZsxNJlNIdW1OZWRZQbZ1fAiqYjZjj4rCdVL2esVsDpOImfCk1d8IIcRmILCOV5Kk/cDI5kStGHRNLIqFtuhZ6T4f6pHamen1qiqE2w3GqrzTBlmWiYxLwGy14a6qxGKzY4uMQjEZz0B7YbyXthOhlrHtKN555x22bdvWuoN1HaHVX3gitK4zaVrDwoULeeyxxzq7Gy1iyZIlHDlypOkduwCK2YwjJpb4lFQi4xOM0Xg7EzJDLoRI68jR+PZVK1h823X85fKLWHzbdWxftaKjmq6HGkar5pqiLYZcMptRoqOBk66JJCFbwzsmuyPRGvnRCydDbtCxhOWIfPuqFXyy+EmcRYUgBM6iQj5Z/GSbjXlHyNhGRkZy5513kp6ezqRJk6iJ4HnuuefIzc0lOzubWbNmUV1djdPppG/fvviOa0NXVFQEtidMmMCdd97JyJEjGTJkCGvWrOHSSy9lwIABPPDAA4H2XnnlFUaNGkVOTg433XRTwFBERkZy//33k52dzejRozl27Bhff/017733HvPnzycnJ4c9e06oSWqaRt++/9/emYdXUaT7/1NnyQpJWIKAcTThIktWkgAJEAJEJIrKIoggDMEFRXEZBxXHUVxw7oxwBfHORfCH4IKDouLCg+NKBASGRcMqEJBoEAhhSULWs72/P85Jm+VkIRs50J/n6Scn3dVVb1f3eU/1W1XfCtUm5hiNRjZs2AA45QkyMzN57vnnuXP2bFKmTeOuv/yFX3NzufH++4np35+UlBRNETItLY2HHnqIAQMGEBYWxgcffAA4x4rff//99OzZk+HDh3PjjTdqxypy5MgRUlNTiYuLIykpiQMHDmCz2ejbty/p6ekAPPnkkzz11FMA/Pvf/yY2Npbo6GhSUlK0fPbv38+QIUMICwtj0aJF2v7Ro0cTFxdHeHg4S5curXTvqtZZuT0JCQlERkby17/+lTZt2mjnzJs3j759+xIVFVVJtrjqM/HnP/+ZqOhovtm4idlzniU2vi8RERFMnz4dEeGDDz5gx44d3HHHHcTExFBSUsLOnTtJTk4mLi6OESNGcOLECbf561wGiEiLb3FxcVKV/fv3V9tXE0vuT5P5t42sti25P63eeVRl79690r17d8nNzRURkTNnzoiIyNmzZ8XhcIiIyOuvvy6PPvqoiIjMmTNHYmNjpbi4WEREHnzwQXnuuedERGTt2rUCaHlVBJB33nlHRESee+45eeCBB0RE5PTp01qap556ShYtWiQiImlpabJmzRrndS9ZopWfnJwsjz/+uIiILFy4ULp06SLHjx+X0tJSufLKK+X06dOyf/9+uemmm8RisYiIyIwZM+TNN9/U7Pj0009FROSxxx6TF154QUREpk6dKqtXr3ZbRyNGjJC9e/fKZ599JvHx8TJ37lwpLS2Va665plKdFBUWir2sTG4aOVJWrFghIiLLli2TUaNGaWWMGzdO7Ha77Nu3T7p16yYiIqtXr5YbbrhB7Ha7nDhxQoKCgtzaMmzYMDl06JCIiGzdulWGDh2q3cOePXvKV199JTExMVJWVianTp2SkJAQ+fnnnyvd1zlz5khiYqKUlpZKbm6utG/fXqun8jTFxcUSHh6u3Zua6mzkyJHy7rvviojI4sWLxd/fX0REvvjiC7nnnnvE4XCI3W6XkSNHynfffVftegD516pV8ltJmWTkF8l3R7MlI79IjpeWyR2TJ2tlJicny/bt20VExGKxSGJiopw6dUpERFatWiXTpk1ze98ag91mk7KSEiktLhKb1dLk+V9sLsTvtAaAHeLGp3pk9//5M+4jODXtrw8tJWNrMBg0edrJkyczduxYAPbu3ctf//pX8vLyKDxfyHUpw7GW2bnzzruYP38eo0ePZvny5bz++uuVygeIjIwkPDycLl26ABAWFkZ2djabNm1i586d9O3bF4CSkhI6dXL2T3t5eWkLUsTFxfHVV1/VWUdJSUls2LCBo0eP8uSTT/L666+TnJys5V9uk59LtXHL1q18tGYNAFOmTOHxxx/X0o0ePRqDwUDv3r21lu2mTZsYP348BoOBzp07M3To0Go2FBYWsnnz5kqLa5TP+AwPD2fKlCncdNNNbNmyBS8vL7Zu3crgwYO1+1Z+X8F5n7y9vfH29qZTp07k5OQQEhLCokWLWOOyOzs7m8zMTDp06FBjnW3ZsoWPP/4YgEmTJjFr1iwAvvzyS7788kv69Omj2Z6ZmcngwYMrXZPRaGTkmDH8XOoMR23fuIEVryygtKSYorw8IsLDufnmmyudc/DgQfbu3cvw4cMB5xtT+f2vDRHBZrHgsNkwGI0YvWqWp7XbbBSePa2NPjGaTAR17opZD5W1OjzSkbft0NEZVnGzv6lpShlbd5RPdkhLS2PNR2voHtaLZa+/weatmzh3soj4mH5kZWWRnp6O3W4nIiJCO9fb9YUyGAza5/L/bTYbIsLUqVP57//+72rlms1mrWyj0VivOP/gwYNZvHgxx48f5/nnn2fevHmkp6eTlJSkpalvnVS0Vy5A78fhcBAUFERGRobb43v27CEoKIhTp05dkA3ldZCens7XX3/Nli1b8PPzY8iQIdps0gutMxHhySef5N577601nY+PD8pgBGyUlZbytz8/wrvpm+gcEsJ78/9ebTZred7h4eFs2bKlzuusSFlxEfk5J7U6b9O+A36BQW6dubWstNIQQrvNRlHeWQKDr2iRGaI69ccj70bS7X/E5FW5VWDy8ibp9j82OM+WkLEFpyMqj/u+++67DBo0CIDz588T3PEK8nIL+fCT97X058+VMnnSZCZNmsS0adMu6JpSUlL44IMPNKd29uxZfvnll1rPadu2LecrfHkr0q9fPzZv3ozBYMDHx4eYmBiWLFlSrYVZzoABA1i1ahUAK1eurOTw3TFw4EA+/PBDHA4HOTk5Wry7IgEBAYSGhrJ69WrA6dB27XJOLP7oo484e/YsGzZs4MEHHyQvL4+EhATtLaK8DmojPz+fdu3a4efnx4EDB9i6dWut6QESEhL48MMPAbTrBRgxYgRvvPEGhYWFAPz22281/sB4GRQmg6LM5bSDOnTAUlzEJ663PKh8b3r06EFubq7myK1WK/v27avVTpvVSkFuTqUfzsKzZ7DXMOPS3X5LSckFywfrND8e6ch7JQ3l+ukzadsxGJSibcdgrp8+k15J1V/F60tFGdvo6GgeffRRAE3GNi4uTgu7uGPOnDls2LCB8PBwPvroI7cytuBssW7bto2IiAi+/fZbnnnmGQBeeOEFBiYN4KZx1/Nf3a79/QSBCRMmcu7cOSZOnHhB19S7d2/mzp3L9ddfT1RUFMOHD6+zQ+z2229n3rx59OnTp1JnJzhbsFdddRUJCQmAM9Ry/vx5IiMj3eb16quvsnz5cqKionj77be15fNq4tZbbyUkJITevXszefJkYmNjCQwMrJZu5cqVLFu2jOjoaMLDw/nkk084ffo0s2fP5v/9v//Htddey8yZM3n44YcJDg5m6dKljB07lujoaLerLlUkNTUVm81Gr169mD17tnat7nA4HOTn5/PMM88wf/58oqKiOHz4sGbz9ddfz6RJk0hMTCQyMpJx48bV+CPpZTAQ6utFl47tGTt1GuMT+/LQ2FH0qxC2SktL47777iMmJga73c4HH3zAE088QXR0NDExMWzevLnWaxOHHYebpe3sboaMAtUaSwDefv764g6tkCaRsb1QLmcZ2zZt2mgttKrYrHbOnSiu1GIyGBXffv85n639jLfffrulzHSLw2pFLBZtSGFzqOgVFhbi5+XF6ZwcEpOT+X7zZjp3brjOfHNhtVo5c+YMDoeDkpISfHx8CAgIYO3ataxatYpPPmmYhpxdBLsIRqWafJUiu83G2d+yKy0yoZSi/ZVXuY172+02is6dozg/D3AKWQVe0RmzGwfvqXia32k2GVudpsNkNhLYyZeCM6U4bA6MJgPPvPgEX3z5BevWravxPIdDsFns2G0OjEYDJi8DBmPTvmw5SkuxZGcjro5FY0AAps6dMTTxRI+RN9xAXu5pLFYLs++6m2A/P0Sk1Qkn2Ww2LcSwe/dubahjhw4dWL58eYPzbQ4HruVtMhF4RWfyc05it9kwGAwEBF9R42Qdo9FE2/Yd8G0bgIgDo9mM0ai7jNaI3iJvhdjtDsQuGIyqTocsDqH4vIWivN+1un3beuEf5I2hiRYSFhFsJ05gqxJfNoeEYAoKapIyABwWC5YjRyrPBFUK727dMFyA5nhLUFJSUq0fRClFcHBwq9eCsdtsOGw2lNGI6TKXTvA0v1NTi9wjY+SXOs5WtbFerWq7zVHJiQOUnLdgtzZhh5TDgd1NOEiqrNbTWMRmqz6dXwSxtr6Zs2azudpIjwtZdu5iYjSZMPv4XPZO/FKidTcddOrEUXVZeBdSw/4GYTBgbNsWm2tETznKz6/pygBnzN1ggEqjIhSqFa7YYzKZ6NChAyUlJdhsNk0bvbWFgHQuD1rfN0TngjCaDBhMBhwVFhRWBoXRXL+XLYfdgc3VejeaDBhN1c9TSmFs3x5HcTEOVyvcGBSEoakduZcX5iuvxHrsmLb2mrlLF1QrFVwym82Y9VatTitAd+QejtFkILCjL4XnSrGW2TF5GWnb3tutQ66K3ebg/JlSLK4ZhUaTgcBgX0xe1cMDBm9vvK6+GofFglIK5e3d5JNClFIYAwIwdOuGWK0ok6lZytHRudTQvyFNSHp6ujaFuzG89tprvPXWW0B1xTt38rhmbyOBnfzo0LUNQZ18MXub6iWjaym1aU4cnI69pNBa40xLZTJh9PPD4OtbybleiCRsVlZWpdmp1cpQCoOPD8a2bauVo1M7DoeD0tJS8vPzKSws1MTWdC59PLZFXvTjKQq+yMKeV4YxyJuAEdfg36dT3Sd6APfdd5/2ecWKFURERNC1a9dazzEYFNQxSqVcYKe8k85WVl0y1VJqQ8Sb1hrqtdlsrX5USENoiiGWJSUl5Ofna/8bjUY6dOhwSdaXTmU8srlT9OMp8j7KxO4arWHPKyPvo0yKfqxbX6M2LkTG9rvvviMmJoaYmBj69OmjzdgrLCxk3Lhx9OzZkzvuuKNa6/bUqVPExcUBsGvXLpRSmrxrt27dKC4u1lq47qRLwTljMjY2lsjISA4cOABQo4xuVlYWPXr04I9//CMRERFkZ2czY8YM4uPj6T8ojpde/hsAP+7aybR778Dbz8Snn36Cr68vFouF0tJSwsLCAPdSu7WRk5PDmDFjiI6OJjo6Wpt5aLfbueeeewgPD+f666/Xrqum/MtnNPbv35/HH3+80bKxrQm7CAU2O1klFn4pKaPQZr8g7RktH7udgioLHtvtdr1VfpngkY684IsspMrwOrE6KPgiq8F57tu3j7lz5/Ltt9+ya9cubTr5oEGD2Lp1Kz/++CO33347L730EgDz58/nn//8JxkZGWzcuFFTQfzxxx9ZuHAh+/fv5+eff+b777+vVE6nTp0oLS2loKCAjRs3Eh8fz8aNG/nll1/o1KkTfhU6EMeNG0d8fDwrV64kIyNDK6Njx4788MMPzJgxQwtpPPfccwwaNIh9+/YxZswY7ccBIDMzk/vvv599+/Zx9dVX8+KLL7Jjxw4yMnbxnx2b2ffTXiLDo9n30158/M1s2rSJiIgItm/fzn/+8x/69+8PwNixY9m+fTu7du2iV69eLFu2rNY6feihh0hOTmbXrl388MMPhIeHa/Y88MAD7Nu3j6CgIE2npLb8jx07xubNm3n55Zd5+OGHefjhh9mzZw8hISFami+//JLMzEy2bdtGRkYGO3fu1DTTWytFNjtHi8sosNnJs9o5UlxGsZtp9HVR/rblbr/OpY9HOnJ7lXHTde2vD7XJ2I4YMYLIyEjmzZunCRMNHDiQRx99lEWLFpGXl6e9vvbr14+QkBAMBgMxMTFkZWVVK2vAgAF8//33bNiwgb/85S9s2LCBjRs31ikqVU659G1cXJyW/4YNG5g8eTJQXUb36quvrqQZ8v777xMbG0t83zgOHPqJ305nERwSwH9170bm4UNs27aNRx99tJpde/fuJSkpicjISFauXFmnSNO3337LjBkzAOdrfrkGSWhoKDExMdWuobb8x48fr43R3rJliyZjO2nSJC1NRdnY2NhYDhw4QGZmZr3q9GLgECHXzRj5fNuFL41nNBorvZmAs79BH1VzeeCRjtwY5F7roab9jeHBBx9k5syZ7NmzhyVLlmiSouUCTSUlJQwcOFALcbiTRq3K4MGDtVb4qFGj2LVrF5s2baq3Iy8vo77ysxWlZY8ePcr8+fP55ptv2L17NyNHjsRms2D2NpGcnMznn3+O2WzmuuuuY9OmTZXsSktL43//93/Zs2cPc+bMcSuveiH2V72G2vKvjzxuuWxsRkYGGRkZHD58mLvuuqtBNnoaSin8/f0JCAjAZDLh4+NDhw4ddEd+mdBoR66UelApdUAptU8p9VJTGFUXASOuQVUZJ63MBgJGXNPgPC9UxvbIkSNERkbyxBNP0LdvX82R14ekpCTeeecdunfvjsFgoH379qxbt06TtK1IbbKyFamvjG5BQQH+/v4EBgaSk5PD559/XsmuhQsXkpiYSHBwMGfOnOHgwYPaKJPz58/TpUsXrFYrK1eurNOmlJQUFi9eDDjjtRU74txR3/ybQja2NWBQimCvKo5WQaCpYbNDy1vlHTt2pF27dni10vH3Ok1Poxy5UmooMAqIFpFwoEWWJffv04mgsd21FrgxyJugsd0bNWrlQmVsFy5cSEREBFFRUZjNZm644YZ6l3XNNdcgIpqO96BBgwgKCnK7qlBF6dKSWqbE11dGNzo6mj59+tCzZ08mTZrEwIEDtWP9+/cnJydHsysqKorIyEhtNMULL7xA//79GThwID179qzzOl955RXWr19PZGQkcXFxdS7qXN/8Fy5cyMsvv1y7bGxEBOPGjqUgL69OOy8Em81GSUkJhYWFlJWVNVqbu43RQJifN+3MRjp4mfgvX2/8Gil4ZjAY9BmmlxmNEs1SSr0PLBWRry/kPF00S6cxFBcX4+vri1KKVatW8a9//UuTjXVYLNhOnMBevjxZYCCmK65oEpVGm83G2bNnK4WzgoKCKnVQ63gWnuZ3mkvG9logSSn1IlAKzBKR7TUYMB2YDtTYWtTRqQ87d+5k5syZiAhBQUG88cYb2jFHQYHmxAHs+fkY/P0xVFirs6FYrdZqfRIFBQV4e3t7hFiWzqVLnY5cKfU14E7Z/ynX+e2BBKAv8L5SKkzcNPNFZCmwFJwt8sYYrXN5k5SUpC3vVhERwV5lLDWA43whNIEjd/f26nA49CF+OhedOh25iFxX0zGl1AzgI5fj3qaUcgAdgeorI+voNDNKKQxt2uCoMlHJ4N80oQ93MyT9/Pz01rjORaexo1Y+BoYCKKWuBbyA2gU+dHSaEWNgIKrCIhQGX18Mbds2Sd5ms1kb0mcwGPD396dNmzZ6x6LORaexMfI3gDeUUnsBCzDVXVhFR6epEJsNsdmcyohuWsjlKo1SVvb72qJNpDWilMLb25sOHTpomjW6E9dpDTTqCRcRCzC5iWzR0akVe3Ex1t9+Q8rKNO1yo5uJQgazGZpxIkzVlYF0dC42+hPZxGRlZWkTcxpCVdnaIUOGUHWo5sVi4cKFdQplNZa0tDQ++OCDavvvuvNOdn/zrbb4s1gsWH/9FYfF0qz26Oh4Ah7ryHfv3s2CBQt49tlnWbBgAbt3777YJgFN78hbE83hyKXCqI/a5AaWvvoqPUOvqXyu3Y40sSMXhwN7URHWU6ewnTmLo4EyBDo6LYlHOvLdu3fz2WefaVO+8/Pz+eyzzxrtzN3J2GZlZTFs2DCioqJISUnRVAXT0tJ46KGHGDBgAGFhYVorcvbs2WzcuJGYmBgWLFhAVlYWSUlJxMbGEhsbq0m5AvzjH/8gMjKS6OhoZs+eXaNsbTlffvkliYmJxMbGMn78eG0q+uzZs+nduzdRUVHMmjULgNWrVxMREUF0dLQ2U7Mi6enpDBkyxK3k7jfffEOfPn2IjIzkzjvvpKysjEWLFnH8+HGGDh3K0KFDK+W1fft2Tcjrk0/cS+BmZGSQkJBAVFQUY8aM4ezp09gLCkgeMICH7rqL+NhYFi5cWCnfp59+mrS0NOx2Oyk33MBOl4hWcL9+zFm0iP633srAYcM0aeHa5G3ri6OoCMvRo9hOncJ64jiWrCyPduYOEUrsDgptdiyNnIWq04opl79syS0uLk6qsn///mr7auLll1+WOXPmVNtefvnleudRlb1790r37t0lNzdXRETOnDkjIiI33XSTrFixQkREli1bJqNGjRIRkalTp8q4cePEbrfLvn37pFu3biIisn79ehk5cqSWb1FRkZSUlIiIyKFDh6T82tetWyeJiYlSVFRUqbzk5GTZvn27dn75/7m5uZKUlCSFhYUiIvL3v/9dnnvuOTl9+rRce+214nA4RETk3LlzIiISEREhx44dq7SvIuvXr5eAgADJzs4Wu90uCQkJsnHjRikpKZGQkBA5ePCgiIhMmTJFFixYICIiV199tVY/FbFarRIaGioiIn/+858lPj5eNm3aJOnp6XL77beLiEhkZKSkp6eLiMjTTz8tD82YIcV79khSfLzcM2GCFO/ZI7bCQpk6daqsXr1aZs2aJffee692XcnJybLlq6+keM8eAWT1q6+K5dQpmTVrlrzwwgsiIjJy5Eh59913RURk8eLF4u/vX8Pddo/DZpPSzEwp3rOn0mZ13RtPw+ZwyMlSi2TkF0lGfpHsLSiWQqvtYpvVqrgQv9MaAHaIG5/qkS3ymsSX6hJlqo2aZGy3bNmiSaVOmTKFTZs2aeeMHj0ag8FA7969tVZhVaxWK/fccw+RkZGMHz9e0xv5+uuvmTZtmja9u30dE1a2bt3K/v37GThwIDExMbz55pv88ssvBAYG4uPjw1133cVHH32k5Tdw4EDS0tJ4/fXXsdvdy6K6k9w9ePAgoaGhXHvttQBMnTq1Tk1vk8lEt27d+Omnn9xK4Obn55OXl0dycjIAf5wypVKe40aMAJyzMsGpuZKfn89rr71WaVSIsW0AXmFheHl5MXraNEzt2xMfH6/J4NYkb1tvRBB3deWhLdkSu4OTZb8vLGET4ViZBZtDH1h2qeGRjrxcJKm++5uLinKsUsOoywULFnDFFVewa9cuduzYgaWBMV0RYfjw4ZpE6/79+1m2bBkmk4lt27Yxbtw41q5dS2pqKuBc93Pu3LlkZ2cTFxenqTrWZH99JXFrYvDgwbVK4NaGplXiGg3St29fdu7cqSlQlqOMBox+fpjNZkz+/iijsdF2V8rfZMLUoUP1/R6opWIXwS7CFd4mgsy/T1gqtQs2fYTwJYdHOvKUlJRqOstms5mUlJQG51mTjO2AAQM0qdSVK1fW6Ziqys7m5+fTpUsXDAYDb7/9ttY6Hj58OMuXL9c6D8vLq0m2NiEhge+//57Dhw8DUFRUxKFDhygsLCQ/P58bb7yRBQsWaFPXjxw5Qv/+/Xn++ecJDg4mOzu7XvXQo0cPsrKytHLefvttrSVdm6RubRK4gYGBtGvXjo0bNwLwzsqVDB4ypHIGSmF0TdxJTU1l9uzZjBw5sl4SvhXryJ287YVgDAzE3KULyssLg58fXtdcg8G1MpOnYHU4+K3UQlaJhZwyG2UOp0MH8DEqTPrY90sOj1yVNSoqCnB2yuXn5xMYGEhKSoq2vyFUlLE1Go306dOHFStW8OqrrzJt2jTmzZtHcHAwy5cvr9M2o9FIdHQ0aWlp3H///dx666289dZbpKamagskpKamkpGRQXx8PF5eXtx444387W9/02RrfX192bJli5ZvcHAwK1asYOLEiZS5huDNnTuXtm3bMmrUKEpLSxERXn75ZQAee+wxMjMzERFSUlKIjo6uVz34+PiwfPlyxo8fj81mo2/fvtpi0NOnTyc1NZWuXbuyfv36Sue5k8A9efKkFhp58803ue+++yguLiYsLIxMBrdOAAAW8klEQVQ3li3Dy8cHZTZjCgrCOzQUVcFhjh8/nvPnz3PLLbewbt26etm+cOFCJk+ezIsvvkhqamqD3tCU2YypQweMgYGgFMoDp98X2h2cs/4eIiqxO/A1KHyNBq70NmOqY5FuHc+jUTK2DUWXsdVpDmqTt72c+K3UwmlL5XCTt0ER6ueNtz6ZqRKe5neaS8ZWR6fVUJu8bUvhEAcWuwW72PEyeGE2tvxSa75uFqZoazLipYdULll0R65zyVCTvG1L4RAH50rPkVOUgyCYDCauansVfuaW7SxtYzQQYDJS4FrE2dug6GA26bowlzC6I9fRaSJKbaWcLDqp/W9z2DhedJxrAq7BZGi5r5qXwcBVPl6UORwITkdu1kMqlzS6I9fRaSKsDmu1fWW2MuwOe4s6cgCTQWEyeF5HrU7D0H+mdXSaCLOhejzcy+iFUXeoOs2M7sh1GoXNZqOoqIjTp09TUFCA1Vq9VXq54G30ppNfJ+1/ozLStU3XFm+N61x+6I68gaSnp1cSwHrttdd46623GpRXa1Y8rA2Hw6FNSLJYLBQWFpKcnMzWrVsvtmkXBaPBSAffDoQFhXF1wNWEBYXhb66ul66j09R4bFPhxMlP+PnIfErLTuDj3YWwbrPo0nlUi5Wfnp5OmzZtGDBgAIA2aaYhrFixgoiICLp27dpU5rUIZWVlbmVta9J2aW6sZXasZXZAMHubMHm1/Ao+BmXA1+RZM0F1PB+PbJGfOPkJBw48RWnZcUAoLTvOgQNPceJk4yZ/jB49mri4OMLDw1m6dKm2/9///jexsbFER0eTkpJCVlYWr732GgsWLCAmJoaNGzfy7LPPMn/+fA4cOEC/fv20c7OysoiMjATg+eefp2/fvkRERDB9+nRExK107c6dO0lOTiYuLo4RI0Zw4sSJarampaUxY8YMEhISCAsLIz09nTvvvJNevXqRlpYGwBtvvMEjjzyinfP666/zpz/9qVpeVa8PYNu2bSQmJtKnTx8GDBjAwYMHAeePzi233MKwYcMYMWIEJSUlzJgxg+TkZO666y5Km1Hy1eEQrGU2ykps2K2VhaysZXbycoopPFdK4bkyzuUUYbNc+A+K3e7AoYtK6Xga7iQR67sBMcBWIAPYAfSrz3mNlbHdtGmQfP1NWLVt06ZB9c7DHeVSssXFxRIeHi6nT5+WU6dOSUhIiPz888+V0syZM0fmzZunnVvx/+joaC393//+d01m9UwFOdTJkyfLp59+KiKVpWstFoskJibKqVOnRERk1apVMm3atGq2Tp06VSZMmCAOh0M+/vhjadu2rezevVvsdrvExsbKjz/+KOfPn5ewsDCxWCwiIpKYmCi7d++ulE9N15efny9Wq1VERL766isZO3asiIgsX75crrzySjlz5ow4HA6ZO3euTJgwQX777Tf56quvxGg0ytatWy+06uvEbrNLwZkSycnKl5ysfDn1a4FYSq3a8fMVjpVv+bnF9c7fZrVL4blSyc0ukDPHC6Ws2KpJ6OpculwqMraNDa28BDwnIp8rpW50/T+kkXnWSWlZ9RZqbfvry6JFi1izZg0A2dnZZGZmkpuby+DBgwkNDQXqlpsFuO2223jvvfeYPXs27733Hu+99x4A69ev56WXXqK4uJizZ88SHh7OzTffXOncgwcPsnfvXoYPHw44wxRdunRxW87NN9+MUorIyEiuuOIKreUfHh5OVlYWMTExDBs2jLVr19KrVy+sVquWppytW7e6vb78/HymTp1KZmYmSqlKnZjDhw/X0m3bto3p06fj7e1N//79iYyMxNgM+iRWi4OS878rR4pDOH+2jKBOBgxGg9tWtMPufMjrCq+ICCWFForzLa7z7OSdKqZdZ3/M3vqIE53WT2MduQABrs+BQIv02Pl4d3GFVarvbyjp6el8/fXXbNmyBT8/P4YMGdLgMMGECRMYP348Y8eORSlF9+7dKS0t5f7772fHjh1cddVVPPvss27zFxHCw8MrCWbVRLkMrcFgqCRJazAYNGnXu+++m7/97W/07NmTadOm1fsann76aYYOHcqaNWvIyspiSAW1Qv8KCx4rpfD19aWDS/61uWLSDnt1TXCbxU65VJC3v4nSosojZnzamutlj8MulBRUH21js9p1R67jETQ2Rv4IME8plQ3MB56sKaFSarpSaodSakdubm6jCg3rNguDoXKHksHgS1i3WQ3OMz8/n3bt2uHn58eBAwe0kRcJCQls2LCBo0ePAnXLzQJ069YNo9HICy+8wIQJEwA0p92xY0cKCwsrLTBcMa8ePXqQm5urOXKr1co+1xJnDaF///5kZ2fz7rvvMnHixGrHa7q+/Px8rrzySsAZF6+JwYMHa2uU7t27t9nWTjWaqj+qXj4mlEvJz+xtIqCjL0azAaPZQEAHX7x86ueElQKDsbrD16e063gKdTpypdTXSqm9brZRwAzgTyJyFfAnYFlN+YjIUhGJF5H44ODgRhndpfMoevZ8ER/vroDCx7srPXu+2KhRK6mpqdhsNnr16sXs2bNJSEgAnPKxS5cuZezYsURHR2uO+eabb2bNmjVaZ2dVJkyYwDvvvMNtt90GQFBQEPfccw8RERGMGDGCvn37amnLpWtjYmKw2+188MEHPPHEE0RHRxMTE1NpmGNDuO222xg4cCDt2rWrdqym63v88cd58skn6dOnT60LN8yYMYPCwkJ69erFM888Q1xcXKNsrQmTlxH/oAoLYZgM+LfzxuBy5AaDwsffTLvOfrS7wh+fNmYM9ZyWbjA686qI0WTA5OWRYwF0LkMaJWOrlMoHgkRElLP5ki8iAXWdp8vYtiw33XQTf/rTnxq18EZrQESwWx3ONQpNBoxuVP4anLdDsFrs2Cx2lEFh9jZiMuthlUsdT/M7NcnYNvabcBxIdn0eBmQ2Mj+dJiQvL49rr70WX19fj3fi4Ax1mLyMmL1NTerEAZRB4eVjwi/AG982XroT1/EoGtvZeQ/wilLKBJQC0xtvkk5TERQUxKFDhy62GTo6Os1Moxy5iGwCmicoqqOjo6NTL/TeHB2dFsThWt1eR6cp8VitFR0dT8IhQqHNTo7FhgCdvEy0NRkx6kMcdZoAvUWuo9MCFNkdHC2xUGx3UGJ38EuJhfO2iyMupnPpoTvyGigXwWoIbdq0AeD48eOMGzeuSexJT0/npptuapK8aiIrK4uIiIhmLaO5WLhwoVslxgvF7rBjc9Q8br6h5Ltx2qetNhx6mEWnCfBYR/7hybPEb95Hl/UZxG/ex4cnz15sk6rRtWvXSjM4Wxu1TfTxNBrryB3i4LzlPEcLjvJz3s+cKTnTpA7d3WBGEwo9sKLTFHikI//w5FlmHczmWJkVAY6VWZl1MLvRzvzFF1/k2muvZdCgQZpsK8CRI0dITU0lLi6OpKQkDhw4AEBOTg5jxowhOjqa6OjoajMwK7ZwV6xYwdixY0lNTaV79+48/vjjWrovv/ySxMREYmNjGT9+PIWFhYBTXrZnz57Exsby0UcfubXZbrcza9YsIiIiiIqK4tVXXwXcS+YCDBkyhEceeYT4+HheeeUVdu7cqdn/z3/+020Z6enpDB48mJEjR9KjRw/uu+8+HA6n9smMGTOIj48nPDycOXPmAPDtt98yevRo7fyvvvqKMWPGAM63lccee4zw8HCuu+46tm3bxpAhQwgLC+PTTz/Vrumxxx6jb9++REVFsWTJEs2OIUOGMG7cOHr27Mkdd9yBiLBo0SKOHz/O0KFDGTp0aO03uQZKbCX8WvArZbYyrA4rJ4tOUlBW0KC83BFoNlIpHK6go5e+sr1OE+FOErG5t8bK2MZ9v1eu+PbHalvc93vrnUdVduzYIREREVJUVCT5+fnSrVs3TZZ22LBhcujQIRER2bp1qwwdOlRERG677TZZsGCBiIjYbDbJy8sTERF/f38RETl69KiEh4eLiFP+NTQ0VPLy8qSkpET+8Ic/yK+//iq5ubmSlJQkhYWFIuKUvX3uueekpKREQkJC5NChQ+JwOGT8+PEycuTIanb/3//9n9x6662a5Gy5DG1tkrkzZszQjkVGRsp3330nIiKzZs3S7K3I+vXrxdvbW44cOSI2m02uu+46Wb16daVybDabJCcny65du8ThcEiPHj00Kd6JEydq5QOybt06EREZPXq0DB8+XCwWi2RkZEh0dLSIiCxZskST/i0tLZW4uDj5+eefZf369RIQECDZ2dlit9slISFBNm7cKCIiV199teTm5tZ8g+sgpyhH9uburbQdOntIbHZbg/OsSpHNJidLLXKitEwKrTZdJrcVoMvYXkR+K3O/LmRN++vDxo0bGTNmDH5+fgDccsstABQWFrJ582bGjx+vpS0rKwOcLc/y5d2MRiOBgYG1lpGSkqKl6d27N7/88gt5eXns37+fgQMHAmCxWEhMTOTAgQOEhobSvXt3ACZPnlxpsYtyvv76a+677z5MJuetLJeXrU0yt1xPJS8vj7y8PAYPHgzAlClT+Pzzz93a3q9fP8LCwgCYOHEimzZtYty4cbz//vssXboUm83GiRMn2L9/P1FRUUyZMoV33nmHadOmsWXLFq2evLy8SE1NBSAyMhJvb2/MZjORkZFkZWUBzjeU3bt3a2Gp/Px8MjMz8fLyol+/foSEhAAQExNDVlYWgwYNqrXe64NR/R78MBvM+Jp8UKppVxjyMxrxawaJXx0dj3TkV3qbOebGaV/pXX0V88bicDgICgoiIyOj0XlVlJo1Go3YbDZEhOHDh/Ovf/2rUtrGlFeXZG5FGdr6UtWhKaU4evQo8+fPZ/v27bRr1460tDStnGnTpnHzzTfj4+PD+PHjtR8as/l3admK8rsVpXdFhFdffZURI0ZUKjM9Pd1tHTYF/mZ/jAYjwT7t8FE2xF6E0eiPOCxg9GmSMnR0mguPjJE/GdYFX0Nlx+JrUDwZ1nA98sGDB/Pxxx9TUlLC+fPn+eyzzwAICAggNDSU1atXA04ns2vXLsDZwl68eDHgjOvm5+dfcLkJCQl8//33HD58GICioiIOHTpEz549ycrK4siRIwDVHH05w4cPZ8mSJZpDO3v2bK2SuRUJCgoiKCiITZs2AbBy5coa7dy2bRtHjx7F4XDw3nvvMWjQIAoKCvD39ycwMJCcnJxKrfmuXbvStWtX5s6de0E66AAjRoxg8eLF2mIWhw4doqioqNZzapMVrg8+Jh/CAkPxkSLs1rM4HGVYrWcpKfkFh6Phb3o6Oi2BRzryWzu3Z36PqwjxNqOAEG8z83tcxa2d6169pyZiY2OZMGEC0dHR3HDDDZVkZleuXMmyZcuIjo4mPDycTz5xrg36yiuvsH79eiIjI4mLi2P//v0XXG5wcDArVqxg4sSJREVFaWEVHx8fli5dysiRI4mNjaVTp05uz7/77rv5wx/+QFRUFNHR0bz77ru1SuZWZfny5TzwwAPExMRoHaLu6Nu3LzNnzqRXr16EhoZqnbx9+vShZ8+eTJo0SQsPlXPHHXdw1VVXXbC63N13303v3r2JjY0lIiKCe++9t86W9/Tp00lNTW1wZyeAEQd2e+UfDIfDgsNR1uA8dXRagkbJ2DYUXcbWs0hPT2f+/PmsXbv2gs6bOXMmffr04a677momy5oWu72EoqLD1fb7+YVhMl14OEqn9eNpfqcmGVuPjJHrtH7i4uLw9/fnf/7nfy62KfXGYPDGbG6P1fr7MFaj0R+DwbuWs3R0Lj66I9epkyFDhlRas7M+7Ny5s3mMaUaUMuDt3QmTyR+brQij0ReTqQ0Gg/410WndtKonVOqx4rmOTnNiMJgxGIIwm4Mutik6zczFCCs3F62ms9PHx4czZ85cUpWro6PTOhERzpw5g4/PpTG0tNW0yENCQjh27Bi5ubkX2xQdHZ3LAB8fH21ymafTahy52WwmNDT0Ypuho6Oj43G0mtCKjo6Ojk7D0B25jo6OjoejO3IdHR0dD+eizOxUSuUCvzRxth2B002cZ1PT2m1s7fZB67extdsHrd/G1m4fXDwbrxaR4Ko7L4ojbw6UUjvcTV1tTbR2G1u7fdD6bWzt9kHrt7G12wetz0Y9tKKjo6Pj4eiOXEdHR8fDuZQcefXlc1ofrd3G1m4ftH4bW7t90PptbO32QSuz8ZKJkevo6OhcrlxKLXIdHR2dyxLdkevo6Oh4OB7lyJVS45VS+5RSDqVUfJVjTyqlDiulDiqlRtRwfqhS6j+udO8ppbya2d73lFIZri1LKeV2RWXXsT2udDvcpWkm+55VSv1WwcYba0iX6qrXw0qp2S1ln6vseUqpA0qp3UqpNUopt/qyLV2HddWJUsrbdf8Pu565a5rbpgplX6WUWq+U2u/6vjzsJs0QpVR+hXv/TEvZV8GGWu+ZcrLIVYe7lVKxLWhbjwp1k6GUKlBKPVIlzUWvQw0R8ZgN6AX0ANKB+Ar7ewO7AG8gFDgCGN2c/z5wu+vza8CMFrT9f4BnajiWBXS8CPX5LDCrjjRGV32GAV6ueu7dgjZeD5hcn/8B/ONi12F96gS4H3jN9fl24L0WrLMuQKzrc1vgkBv7hgBrW/qZu5B7BtwIfA4oIAH4z0Wy0wicxDkZp1XVYfnmUS1yEflJRA66OTQKWCUiZSJyFDgM9KuYQDlXrBgGlC8p/yYwujntrVL2bcC/WqK8JqYfcFhEfhYRC7AKZ323CCLypYiUr7y8FWgNuqP1qZNROJ8xcD5zKaqFVk0RkRMi8oPr83ngJ+DKlii7iRkFvCVOtgJBSqkuF8GOFOCIiDT1bPQmw6MceS1cCWRX+P8Y1R/cDkBeBafgLk1zkQTkiEhmDccF+FIptVMpNb2FbCpnpuu19Q2lVDs3x+tTty3FnThbaO5oyTqsT51oaVzPXD7OZ7BFcYV0+gD/cXM4USm1Syn1uVIqvEUNc1LXPWstz97t1NwIu9h1CLQiPfJylFJfA53dHHpKRD5paXvqop72TqT21vggEflNKdUJ+EopdUBENjS3fcBi4AWcX6gXcIZ/7myKci+E+tShUuopwAasrCGbZqtDT0Up1Qb4EHhERAqqHP4BZ6ig0NU38jHQvYVNbPX3zNWPdgvwpJvDraEOgVboyEXkugac9htwVYX/Q1z7KnIG56uZydVCcpfmgqnLXqWUCRgLxNWSx2+uv6eUUmtwvro3yQNd3/pUSr0OrHVzqD512yjqUYdpwE1AiriCk27yaLY6dEN96qQ8zTHXMxCI8xlsEZRSZpxOfKWIfFT1eEXHLiLrlFL/p5TqKCItJgRVj3vW7M9ePbgB+EFEcqoeaA11WM6lElr5FLjdNVIgFOev4raKCVwOYD0wzrVrKtASLfzrgAMicszdQaWUv1KqbflnnJ17e1vALqrEG8fUUO52oLtyjvjxwvma+WlL2AfO0SHA48AtIlJcQ5qWrsP61MmnOJ8xcD5z39b0I9TUuGLxy4CfROTlGtJ0Lo/ZK6X64fQFLflDU5979inwR9folQQgX0ROtJSNLmp8m77YdViJi93beiEbTmdzDCgDcoAvKhx7CudIgoPADRX2rwO6uj6H4XTwh4HVgHcL2LwCuK/Kvq7Augo27XJt+3CGE1qqPt8G9gC7cX5pulS1z/X/jThHPhxpSftcZR/GGSfNcG2vVbXxYtShuzoBnsf5gwPg43rGDrueubAWrLNBOMNluyvU243AfeXPIjDTVVe7cHYiD2jh++r2nlWxUQH/dNXxHiqMVGshG/1xOubACvtaTR1W3PQp+jo6OjoezqUSWtHR0dG5bNEduY6Ojo6HoztyHR0dHQ9Hd+Q6Ojo6Ho7uyHV0dHQ8HN2R6+jo6Hg4uiPX0dHR8XD+P8LSURiv3eGaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy1xv013SzEp"
      },
      "source": [
        "sns.scatterplot(snn_emb[:,0], snn_emb[:,1], hue = emb_lab)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.xlabel(\"Embedding Dim 1\")\n",
        "plt.ylabel(\"Embedding Dim 2\")\n",
        "plt.title(\"PSNN Query Embeddings - Training\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSxZN8m8X5NT"
      },
      "source": [
        "emb_sample_ix = [i for i in range(len(test_labels)) if test_labels[i] in a]\n",
        "emb_sample_ix = np.random.choice(emb_sample_ix, size = 100, replace = False)\n",
        "\n",
        "SBERT_embedding = np.zeros((len(emb_sample_ix), 768))\n",
        "SNN_embedding = np.zeros((len(emb_sample_ix), PseudoSiamese.output_size))\n",
        "emb_lab = []\n",
        "\n",
        "for i in range(len(emb_sample_ix)):\n",
        "  ix = emb_sample_ix[i]\n",
        "  query = test_queries[ix]\n",
        "  label = test_labels[ix]\n",
        "  emb_lab.append(label)\n",
        "\n",
        "  # embed with SBERT \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "  SBERT_embedding[i,:] = query_embeddings_LM.detach().cpu().numpy()\n",
        "\n",
        "  # embed with PSNN\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  SNN_embedding[i,:] = query_embeddings_SNN.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "emb_lab = [label_map[x] for x in emb_lab]\n",
        "lm_emb = TSNE(n_components=2).fit_transform(SBERT_embedding)\n",
        "snn_emb = TSNE(n_components=2).fit_transform(SNN_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBqM9upKYYbi"
      },
      "source": [
        "sns.scatterplot(lm_emb[:,0], lm_emb[:,1], hue = emb_lab,)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.xlabel(\"Embedding Dim 1\")\n",
        "plt.ylabel(\"Embedding Dim 2\")\n",
        "plt.title(\"SBERT Query Embeddings - Testing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P5O1JXeYYbi"
      },
      "source": [
        "sns.scatterplot(snn_emb[:,0], snn_emb[:,1], hue = emb_lab)\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.xlabel(\"Embedding Dim 1\")\n",
        "plt.ylabel(\"Embedding Dim 2\")\n",
        "plt.title(\"PSNN Query Embeddings - Testing\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3FSshELLWjB"
      },
      "source": [
        "# Stack ZSL on top of another model\n",
        "\n",
        "As it turns out, this doesn't help SNN, but it does help the centroid method "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9M3Q4GsEpW8"
      },
      "source": [
        "# from functools import reduce\n",
        "top_k = 3 # the number of items to gather from each model \n",
        "n_correct_ZSL_stackSNN = 0\n",
        "n_correct_ZSL_stackCENT = 0\n",
        "n_correct_ZSL_stackUNION = 0\n",
        "for ix in range(len(test_queries)):\n",
        "  query = test_queries[ix]\n",
        "  label = label_map[test_labels[ix]]\n",
        "\n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  top_intents = torch.topk(torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), k = top_k, largest = False).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_SNN = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_SNN.append(label_map[label_ix])\n",
        "\n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "\n",
        "  top_intents = torch.topk(torch.inner(query_embeddings_LM, intents_embeddings_raw), k = top_k).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  top_intents_SBERT = []\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_SBERT.append(label_map[label_ix])\n",
        "\n",
        "  top_intents_CENTROID = []\n",
        "  top_intents = torch.topk(torch.inner(query_embeddings_LM, intent_centroids_lm), k = top_k).indices.squeeze()\n",
        "  if top_k == 1:\n",
        "    top_intents = [top_intents]\n",
        "  for i in range(len(top_intents)):\n",
        "    label_ix = intent_set[top_intents[i].item()]\n",
        "    top_intents_CENTROID.append(label_map[label_ix])\n",
        "\n",
        "  # # # use one of the above models as the suggestion engine for ZSL\n",
        "  pred_ZSL = classifier(query, top_intents_CENTROID)\n",
        "  if pred_ZSL['labels'][0] == label:\n",
        "    n_correct_ZSL_stackCENT +=1 \n",
        "\n",
        "      # # use one of the above models as the suggestion engine for ZSL\n",
        "  pred_ZSL = classifier(query, top_intents_SNN)\n",
        "  if pred_ZSL['labels'][0] == label:\n",
        "    n_correct_ZSL_stackSNN +=1 \n",
        "\n",
        "  # # # use one of the above models as the suggestion engine for ZSL\n",
        "  pred_ZSL = classifier(query, list(set(top_intents_SNN).union(set(top_intents_CENTROID))))\n",
        "  if pred_ZSL['labels'][0] == label:\n",
        "    n_correct_ZSL_stackUNION +=1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkADp4q2xnTh",
        "outputId": "62247e15-c534-4788-9353-bb6e43684245"
      },
      "source": [
        "print(\"Centroid \", n_correct_ZSL_stackCENT)\n",
        "print(\"SNN \", n_correct_ZSL_stackSNN)\n",
        "print(\"Union \", n_correct_ZSL_stackUNION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Centroid  654\n",
            "SNN  712\n",
            "Union  676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DotaMPI72rfo"
      },
      "source": [
        "Close out the project with one more task \n",
        "- Ensemble: find some smart way of using the confidence scores from the NN/SBERT/SNN models and then combining them\n",
        "- RL: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BcjTplqe_bB"
      },
      "source": [
        "# Do manual remapping\n",
        "label_map_ZSL = label_map.copy()\n",
        "label_map_ZSL[0] = 'activate card'\n",
        "label_map_ZSL[17] = 'wrong or incorrect exchange rate'\n",
        "label_map_ZSL[19] = 'withdrawal charge'\n",
        "label_map_ZSL[34] = 'extra charge'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0F_5Yg23ZvDH"
      },
      "source": [
        "# hypotheses_set = [top_intents_SNN, top_intents_SBERT, top_intents_CENTROID]\n",
        "# list(reduce(set.intersection, [set(item) for item in hypotheses_set]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz_qpcPd4L_G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m57S49yNGi91"
      },
      "source": [
        "# Enesemble method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEWU3g2YGiJz"
      },
      "source": [
        "from sklearn.preprocessing import quantile_transform\n",
        "\n",
        "# Score in a loop\n",
        "n_models = 3 \n",
        "pred_train = np.zeros((len(train_queries), n_models*len(intent_set)))\n",
        "\n",
        "for ix in range(len(train_queries)):\n",
        "  query = train_queries[ix]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  preds_SNN = F.softmax(1/torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)  # take softmax over inverse distance (closer is better)\n",
        "\n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "\n",
        "  preds_SBERT = F.softmax(torch.inner(query_embeddings_LM, intents_embeddings_raw), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)\n",
        "\n",
        "  preds_CENTROID = F.softmax(torch.inner(query_embeddings_LM, intent_centroids_lm), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)\n",
        "\n",
        "  pred_train[ix,:] = np.concatenate([quantile_transform(preds_SNN, n_quantiles = len(intent_set), copy = True), \n",
        "                                  quantile_transform(preds_SBERT, n_quantiles = len(intent_set), copy = True),\n",
        "                                  quantile_transform(preds_CENTROID, n_quantiles = len(intent_set), copy = True)], axis = 0).squeeze()\n",
        "\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2org-FGyZL59",
        "outputId": "40ec27fa-d33f-4c74-93ef-b4d7fef900ab"
      },
      "source": [
        "X_train = pred_train\n",
        "y_train = train_labels\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(600, 90)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbZQkomZZrio"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "rf = RandomForestClassifier(random_state = 6864)\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 500, num = 10)]\n",
        "# Degree of regularization on each tree\n",
        "ccp_alpha = [x for x in np.logspace(start = -8, stop = 1, num = 10)]\n",
        "ccp_alpha.append(0)\n",
        "# Number of features to consider at every split, including all features \n",
        "max_features = ['auto', 0.5, 0.7, 0.8, 0.9, None]\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 100, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 3, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4, 5]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'ccp_alpha':ccp_alpha,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywK2VqMZaXtm",
        "outputId": "d4273875-fdd2-4999-c66f-a0565e635f63"
      },
      "source": [
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 300, cv = 5, verbose=2, random_state=6864, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)\n",
        "\n",
        "rf_random.best_estimator_\n",
        "\n",
        "ens_clf = rf_random.best_estimator_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   34.6s\n",
            "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 19.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 28.4min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZV0IBCAarR4"
      },
      "source": [
        "# Score in a loop\n",
        "n_models = 3 \n",
        "pred_test = np.zeros((len(test_queries), n_models*len(intent_set)))\n",
        "\n",
        "for ix in range(len(test_queries)):\n",
        "  query = test_queries[ix]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  preds_SNN = F.softmax(1/torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)  # take softmax over inverse distance (closer is better)\n",
        "  # they're too close together sometimes, so do a quantile transform\n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "\n",
        "  preds_SBERT = F.softmax(torch.inner(query_embeddings_LM, intents_embeddings_raw), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)\n",
        "\n",
        "  preds_CENTROID = F.softmax(torch.inner(query_embeddings_LM, intent_centroids_lm), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)\n",
        "\n",
        "  pred_test[ix,:] = np.concatenate([quantile_transform(preds_SNN, n_quantiles = len(intent_set), copy = True), \n",
        "                                    quantile_transform(preds_SBERT, n_quantiles = len(intent_set), copy = True),\n",
        "                                    quantile_transform(preds_CENTROID, n_quantiles = len(intent_set), copy = True)], axis = 0).squeeze()\n",
        "\n",
        "X_test = pred_test\n",
        "y_test = test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3O_-4l-fbIqE",
        "outputId": "e78fd04c-b55c-469f-c297-f3a0871e1c11"
      },
      "source": [
        "pred_test_ens = ens_clf.predict(X_test)\n",
        "pred_test_ens_p = ens_clf.predict_proba(X_test)\n",
        "\n",
        "np.sum(pred_test_ens==y_test)/len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XuuIuS1urKv"
      },
      "source": [
        "# Now lets use the ensemble to create an augmented dataset with pseudolabels \n",
        "\n",
        "# Score in a loop\n",
        "n_models = 3 \n",
        "pred_test = np.zeros((len(holdout_queries), n_models*len(intent_set)))\n",
        "\n",
        "for ix in range(len(holdout_queries)):\n",
        "  query = holdout_queries[ix]\n",
        "\n",
        "  # LM + SNN's FF layer \n",
        "  encoded_query = tokenizer(query, padding=True, truncation=True,return_token_type_ids=False, max_length=128, return_tensors='pt')\n",
        "  encoded_query.to(device)\n",
        "  query_embeddings_SNN = PseudoSiamese.forward_one(encoded_query)\n",
        "  preds_SNN = F.softmax(1/torch.norm(query_embeddings_SNN-intents_embeddings, 2, dim = 1), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)  # take softmax over inverse distance (closer is better)\n",
        "  # they're too close together sometimes, so do a quantile transform\n",
        "  lm_enc = lm(**encoded_query) # ONLY use the language model\n",
        "  query_embeddings_LM = mean_pooling(lm_enc, encoded_query['attention_mask']) \n",
        "\n",
        "  preds_SBERT = F.softmax(torch.inner(query_embeddings_LM, intents_embeddings_raw), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)\n",
        "\n",
        "  preds_CENTROID = F.softmax(torch.inner(query_embeddings_LM, intent_centroids_lm), dim=-1).squeeze().detach().cpu().numpy().reshape(-1,1)\n",
        "\n",
        "  pred_test[ix,:] = np.concatenate([quantile_transform(preds_SNN, n_quantiles = len(intent_set), copy = True), \n",
        "                                    quantile_transform(preds_SBERT, n_quantiles = len(intent_set), copy = True),\n",
        "                                    quantile_transform(preds_CENTROID, n_quantiles = len(intent_set), copy = True)], axis = 0).squeeze()\n",
        "\n",
        "X_test = pred_test\n",
        "y_test = holdout_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH8IuzXnHi7q",
        "outputId": "404a924d-0743-4dcb-aaea-5d37b4b0a8f2"
      },
      "source": [
        "pred_test_ens = ens_clf.predict(X_test)\n",
        "pred_test_ens_p = ens_clf.predict_proba(X_test)\n",
        "\n",
        "np.sum(pred_test_ens==y_test)/len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8221979820016362"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-L7J3KWugWk"
      },
      "source": [
        "# look at ensemble output and grab the queries that we're most confident in across each label\n",
        "probs = np.argmax(pred_test_ens_p, axis=1)\n",
        "pseudo_probs = [pred_test_ens_p[i,probs[i]] for i in range(len(probs))]\n",
        "pseudo_labels = pred_test_ens \n",
        "pseudo_df = pd.DataFrame({'query': holdout_queries, 'label':y_test ,'pseudolabel': pseudo_labels, 'prob': pseudo_probs})\n",
        "pseudo_df[\"rank\"] = pseudo_df.groupby(\"pseudolabel\")[\"prob\"].rank(\"dense\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSa9fYGfL6LD"
      },
      "source": [
        "pseudo_df.to_csv('Pseudo_trainingdata{}.csv'.format(n_samples), index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}